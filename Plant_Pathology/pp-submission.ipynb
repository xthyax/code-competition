{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sacred-demand",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-05-19T09:03:16.173278Z",
     "iopub.status.busy": "2021-05-19T09:03:16.171762Z",
     "iopub.status.idle": "2021-05-19T09:03:17.148807Z",
     "shell.execute_reply": "2021-05-19T09:03:17.147998Z"
    },
    "papermill": {
     "duration": 0.99248,
     "end_time": "2021-05-19T09:03:17.149036",
     "exception": false,
     "start_time": "2021-05-19T09:03:16.156556",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import os\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"3\" # \"6\"\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"2\" # \"4\"\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"3\" # \"6\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fitted-original",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-19T09:03:17.194404Z",
     "iopub.status.busy": "2021-05-19T09:03:17.193343Z",
     "iopub.status.idle": "2021-05-19T09:03:17.203720Z",
     "shell.execute_reply": "2021-05-19T09:03:17.204378Z"
    },
    "papermill": {
     "duration": 0.035556,
     "end_time": "2021-05-19T09:03:17.204554",
     "exception": false,
     "start_time": "2021-05-19T09:03:17.168998",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../input/plant-pathology-2021-fgvc8/test_images/ad8770db05586b59.jpg', '../input/plant-pathology-2021-fgvc8/test_images/c7b03e718489f3ca.jpg', '../input/plant-pathology-2021-fgvc8/test_images/85f8cb619c66b863.jpg']\n",
      "this submission notebook will compute CV score, but commit notebook will not\n"
     ]
    }
   ],
   "source": [
    "source_folder = r\"../input/plant-pathology-2021-fgvc8\"\n",
    "\n",
    "test = glob.glob(os.path.join(source_folder, \"test_images\",\"*\"))\n",
    "\n",
    "print(test)\n",
    "if len(test)>3: \n",
    "    GET_CV = False\n",
    "    \n",
    "else: \n",
    "    GET_CV =True\n",
    "    print('this submission notebook will compute CV score, but commit notebook will not')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "funky-prerequisite",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-19T09:03:17.249337Z",
     "iopub.status.busy": "2021-05-19T09:03:17.247571Z",
     "iopub.status.idle": "2021-05-19T09:03:17.250858Z",
     "shell.execute_reply": "2021-05-19T09:03:17.250241Z"
    },
    "papermill": {
     "duration": 0.026948,
     "end_time": "2021-05-19T09:03:17.251000",
     "exception": false,
     "start_time": "2021-05-19T09:03:17.224052",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../input/classification-nn-pytorch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "spoken-bradley",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-19T09:03:17.296546Z",
     "iopub.status.busy": "2021-05-19T09:03:17.295805Z",
     "iopub.status.idle": "2021-05-19T09:03:20.357858Z",
     "shell.execute_reply": "2021-05-19T09:03:20.357370Z"
    },
    "papermill": {
     "duration": 3.088147,
     "end_time": "2021-05-19T09:03:20.357998",
     "exception": false,
     "start_time": "2021-05-19T09:03:17.269851",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Preliminaries\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, MultiLabelBinarizer\n",
    "\n",
    "import cv2\n",
    "cv2.setNumThreads(0)\n",
    "cv2.ocl.setUseOpenCL(False)\n",
    "\n",
    "# albumentations for augs\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "# torch\n",
    "import torch\n",
    "from classification_nn_pytorch import EfficientNet\n",
    "import torch.nn as nn\n",
    "from torch.nn import Parameter\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam, lr_scheduler\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "import ttach as tta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assigned-summer",
   "metadata": {
    "papermill": {
     "duration": 0.010733,
     "end_time": "2021-05-19T09:03:20.380076",
     "exception": false,
     "start_time": "2021-05-19T09:03:20.369343",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "south-gossip",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-19T09:03:20.450896Z",
     "iopub.status.busy": "2021-05-19T09:03:20.450255Z",
     "iopub.status.idle": "2021-05-19T09:03:20.453451Z",
     "shell.execute_reply": "2021-05-19T09:03:20.452698Z"
    },
    "papermill": {
     "duration": 0.062637,
     "end_time": "2021-05-19T09:03:20.453565",
     "exception": false,
     "start_time": "2021-05-19T09:03:20.390928",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    root = r\"../input/plant-pathology-2021-fgvc8\"\n",
    "\n",
    "    dup_csv_path = r\"../input/pp-trained-models/duplicates.csv\"\n",
    "    classes = [\n",
    "        'complex', \n",
    "        'frog_eye_leaf_spot', \n",
    "        'powdery_mildew', \n",
    "        'rust', \n",
    "        'scab',\n",
    "        'healthy'\n",
    "    ]\n",
    "\n",
    "    pretrained_path = None\n",
    "\n",
    "    models_path = r\"../input/pp-trained-models\"\n",
    "\n",
    "    model_name = 'efficientnet-b4' \n",
    "\n",
    "    lr_rate = 1e-4\n",
    "    seed = 42\n",
    "    num_gpus = 1\n",
    "    num_workers = min(8,num_gpus * 2) if num_gpus > 1 else 2\n",
    "    batch_size = 16 * num_gpus\n",
    "    img_size = 256\n",
    "    folds = 5\n",
    "    transform = True\n",
    "    epochs = 100\n",
    "    patient = 10\n",
    "\n",
    "    tta_option = tta.Compose([\n",
    "                    tta.Rotate90([0, 90, 180, 270])\n",
    "                ])\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threatened-catalyst",
   "metadata": {
    "papermill": {
     "duration": 0.011052,
     "end_time": "2021-05-19T09:03:20.475792",
     "exception": false,
     "start_time": "2021-05-19T09:03:20.464740",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adequate-shadow",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-19T09:03:20.510910Z",
     "iopub.status.busy": "2021-05-19T09:03:20.509706Z",
     "iopub.status.idle": "2021-05-19T09:03:20.512318Z",
     "shell.execute_reply": "2021-05-19T09:03:20.511933Z"
    },
    "papermill": {
     "duration": 0.02549,
     "end_time": "2021-05-19T09:03:20.512421",
     "exception": false,
     "start_time": "2021-05-19T09:03:20.486931",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Preprocess:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def get_train_transforms():\n",
    "        return A.Compose(\n",
    "            [\n",
    "                A.OneOf([\n",
    "                    A.RGBShift(),\n",
    "                    A.ChannelShuffle(),\n",
    "                ], p=0.2),\n",
    "\n",
    "                A.RandomResizedCrop(CFG.img_size, CFG.img_size, scale=(0.9, 1), p=1),\n",
    "                A.HorizontalFlip(p=0.5),\n",
    "                A.VerticalFlip(p=0.5),\n",
    "                A.ShiftScaleRotate(p=0.5),\n",
    "                A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=50, p=0.7),\n",
    "                A.RandomBrightnessContrast(brightness_limit=(-0.2,0.2), contrast_limit=(-0.2, 0.2), p=0.7),\n",
    "                A.CLAHE(clip_limit=(1,4), p=0.5),\n",
    "\n",
    "                A.OneOf([\n",
    "                    A.OpticalDistortion(distort_limit=1.0),\n",
    "                    A.GridDistortion(num_steps=5, distort_limit=0.7),\n",
    "                    A.ElasticTransform(alpha=3),\n",
    "                ], p=0.2),\n",
    "\n",
    "                A.OneOf([\n",
    "                    A.GaussNoise(var_limit=[10, 50]),\n",
    "                    A.GaussianBlur(),\n",
    "                    A.MotionBlur(),\n",
    "                    A.MedianBlur(),\n",
    "                ], p=0.2),\n",
    "\n",
    "                A.OneOf([\n",
    "                    # A.RandomSunFlare(), \n",
    "                    A.RandomFog(fog_coef_lower=0.3, fog_coef_upper=0.5, alpha_coef=0.1),\n",
    "                    A.RandomBrightness(limit=0.3, p=1),\n",
    "                ], p=0.2),\n",
    "\n",
    "                A.Resize(CFG.img_size, CFG.img_size, always_apply=True),\n",
    "\n",
    "                A.OneOf([\n",
    "                    A.JpegCompression(),\n",
    "                    A.Downscale(scale_min=0.1, scale_max=0.15),\n",
    "                ], p=0.2),\n",
    "\n",
    "                A.IAAPiecewiseAffine(p=0.2),\n",
    "                A.IAASharpen(p=0.2),\n",
    "                A.Cutout(max_h_size=int(CFG.img_size * 0.1), max_w_size=int(CFG.img_size * 0.1), num_holes=5, p=0.5),\n",
    "                A.Normalize(),\n",
    "                ToTensorV2(p=1.0)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def get_valid_transforms():\n",
    "        \n",
    "        return A.Compose(\n",
    "        [\n",
    "            A.Resize(CFG.img_size, CFG.img_size, always_apply=True),\n",
    "            A.Normalize(),\n",
    "            ToTensorV2(p=1.0)\n",
    "        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "resistant-values",
   "metadata": {
    "papermill": {
     "duration": 0.011052,
     "end_time": "2021-05-19T09:03:20.534510",
     "exception": false,
     "start_time": "2021-05-19T09:03:20.523458",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "liquid-native",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-19T09:03:20.563167Z",
     "iopub.status.busy": "2021-05-19T09:03:20.562533Z",
     "iopub.status.idle": "2021-05-19T09:03:20.565952Z",
     "shell.execute_reply": "2021-05-19T09:03:20.565551Z"
    },
    "papermill": {
     "duration": 0.020419,
     "end_time": "2021-05-19T09:03:20.566056",
     "exception": false,
     "start_time": "2021-05-19T09:03:20.545637",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PPDataset(Dataset):\n",
    "    def __init__(self, csv, transforms=None, training=True):\n",
    "        self.csv = csv.reset_index()\n",
    "        self.augmentations = transforms\n",
    "        self.training = training\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.csv.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.csv.iloc[index]\n",
    "        \n",
    "        image = cv2.imread(row.filepath)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        if self.augmentations:\n",
    "            augmented = self.augmentations(image=image)\n",
    "            image = augmented['image']\n",
    "            \n",
    "        if self.training:\n",
    "            return image, torch.tensor(row[1:len(CFG.classes)+1])\n",
    "        \n",
    "        else:\n",
    "            return image, torch.tensor(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cognitive-andorra",
   "metadata": {
    "papermill": {
     "duration": 0.01104,
     "end_time": "2021-05-19T09:03:20.589265",
     "exception": false,
     "start_time": "2021-05-19T09:03:20.578225",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "wound-operations",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-19T09:03:20.619649Z",
     "iopub.status.busy": "2021-05-19T09:03:20.618445Z",
     "iopub.status.idle": "2021-05-19T09:03:20.621156Z",
     "shell.execute_reply": "2021-05-19T09:03:20.620706Z"
    },
    "papermill": {
     "duration": 0.020843,
     "end_time": "2021-05-19T09:03:20.621258",
     "exception": false,
     "start_time": "2021-05-19T09:03:20.600415",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Create_model:\n",
    "    def __init__(self, CFG, pretrain_option=True):\n",
    "        self.config = CFG\n",
    "        self.pretrain_option = pretrain_option\n",
    "\n",
    "    def _build_model(self):\n",
    "\n",
    "        if self.pretrain_option:\n",
    "            print(\"Loading pretrained :\", self.config.pretrained_path)\n",
    "            model = EfficientNet.from_pretrained(\n",
    "                                                    self.config.model_name,\n",
    "                                                    weights_path=self.config.pretrained_path,\n",
    "                                                    advprop=False,\n",
    "                                                    num_classes=len(self.config.classes),\n",
    "                                                    image_size=self.config.img_size\n",
    "                                                )\n",
    "        \n",
    "        else:\n",
    "            print(f'Buidling Model Backbone for {self.config.model_name} model.')\n",
    "            model =  EfficientNet.from_name(\n",
    "                                                self.config.model_name,\n",
    "                                                num_classes=len(self.config.classes),\n",
    "                                                image_size=self.config.img_size\n",
    "                                            )\n",
    "\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "difficult-sight",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-19T09:03:20.669774Z",
     "iopub.status.busy": "2021-05-19T09:03:20.668456Z",
     "iopub.status.idle": "2021-05-19T09:03:20.670779Z",
     "shell.execute_reply": "2021-05-19T09:03:20.671229Z"
    },
    "papermill": {
     "duration": 0.038617,
     "end_time": "2021-05-19T09:03:20.671340",
     "exception": false,
     "start_time": "2021-05-19T09:03:20.632723",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Main_session:\n",
    "    def __init__(self, GET_CV, CFG):\n",
    "        self.GET_CV = GET_CV\n",
    "        self.config = CFG\n",
    "        \n",
    "    def read_dataset(self):\n",
    "        if self.GET_CV:\n",
    "            df = pd.read_csv(os.path.join(self.config.root, 'train.csv'), index_col='image')\n",
    "            init_len = len(df)\n",
    "            \n",
    "            with open(self.config.dup_csv_path, 'r') as file:\n",
    "                duplicates = [x.strip().split(\",\") for x in file.readlines()]\n",
    "\n",
    "            for row in duplicates:\n",
    "                unique_labels = df.loc[row].drop_duplicates().values\n",
    "                if len(unique_labels)  == 1:\n",
    "                    df = df.drop(row[1:], axis=0)\n",
    "\n",
    "                else:\n",
    "                    df = df.drop(row, axis=0)\n",
    "\n",
    "            print(f\"Dropping {init_len - len(df)} duplicates samples\")\n",
    "\n",
    "            original_labels = df['labels'].values.copy()\n",
    "            \n",
    "            df['labels'] = [x.split(' ') for x in df['labels']]\n",
    "\n",
    "            labels = MultiLabelBinarizer(classes=self.config.classes).fit_transform(df['labels'].values)\n",
    "\n",
    "            df = pd.DataFrame(columns=self.config.classes, data=labels, index=df.index)\n",
    "            \n",
    "            skf = StratifiedKFold(n_splits=self.config.folds, shuffle=True, random_state=self.config.seed)\n",
    "            # skf.get_n_splits(df.index, df['label_group'])\n",
    "            np_fold = np.zeros((len(df),))\n",
    "            df['fold'] = 0\n",
    "\n",
    "            for i, (train_index, test_index) in enumerate(skf.split(df.index, original_labels)):\n",
    "\n",
    "                df['fold'].iloc[test_index] = i\n",
    "                np_fold[test_index] = i\n",
    "\n",
    "            # df['filepath'] = df.index.apply(lambda x: os.path.join(CFG.root, 'train_images',x))\n",
    "            value_counts = lambda x: pd.Series.value_counts(x, normalize=True)\n",
    "            \n",
    "            df_check = df.drop(columns=['fold'])\n",
    "            # print(df_check[np_fold == 0].apply(value_counts).loc[1])\n",
    "\n",
    "            df_occurence = pd.DataFrame({\n",
    "                \"origin\": df_check.apply(value_counts).loc[1],\n",
    "                'fold_0': df_check[np_fold == 0].apply(value_counts).loc[1],\n",
    "                'fold_1': df_check[np_fold == 1].apply(value_counts).loc[1],\n",
    "                'fold_2': df_check[np_fold == 2].apply(value_counts).loc[1],\n",
    "                'fold_3': df_check[np_fold == 3].apply(value_counts).loc[1],\n",
    "                'fold_4': df_check[np_fold == 4].apply(value_counts).loc[1],\n",
    "            })\n",
    "\n",
    "            # print(df_occurence)\n",
    "            df['image'] = df.index\n",
    "            df['origin_labels'] = original_labels\n",
    "            df['filepath'] = df['image'].apply(lambda x: os.path.join(self.config.root, 'train_images',x))\n",
    "\n",
    "        else:\n",
    "            test_path = glob.glob(os.path.join(source_folder, \"test_images\",\"*\"))\n",
    "            test_images = [path.split(\"/\")[-1] for path in test_path]\n",
    "            df = pd.DataFrame(columns=['image'], data=test_images)\n",
    "\n",
    "            df['filepath'] = df['image'].apply(lambda x: os.path.join(self.config.root, 'test_images',x))\n",
    "\n",
    "        return df\n",
    "\n",
    "    def get_predict_results(self):\n",
    "        data = self.read_dataset()\n",
    "        data = data.reset_index(drop=True)\n",
    "        \n",
    "        list_models = [0] * self.config.folds\n",
    "        \n",
    "        probs_dict = {}\n",
    "        \n",
    "        for i in [0]:\n",
    "            probs_list = []\n",
    "            preds_list = []\n",
    "            \n",
    "            model = Create_model(self.config, pretrain_option=False)\n",
    "            \n",
    "            list_models[i] = model._build_model()\n",
    "            model_path = os.path.join(self.config.models_path, f'model_{self.config.model_name}_IMG_SIZE_{self.config.img_size}_f{i}.pth')\n",
    "            \n",
    "            list_models[i].load_state_dict(torch.load(model_path), strict=False)\n",
    "            list_models[i].to(device=self.config.device)\n",
    "            list_models[i].eval()\n",
    "            \n",
    "            if self.config.num_gpus > 1:\n",
    "                list_models[i] = tta.ClassificationTTAWrapper(list_models[i].module, self.config.tta_option)\n",
    "                list_models[i] = nn.DataParallel(list_models[i])\n",
    "\n",
    "            else:\n",
    "                list_models[i] = tta.ClassificationTTAWrapper(list_models[i], self.config.tta_option)\n",
    "            \n",
    "            list_models[i].eval()\n",
    "            \n",
    "            image_dataset = PPDataset(data, transforms=Preprocess.get_valid_transforms(), training= self.GET_CV)\n",
    "\n",
    "            image_loader = DataLoader(\n",
    "                image_dataset,\n",
    "                batch_size=self.config.batch_size,\n",
    "                pin_memory=True,\n",
    "                drop_last=False,\n",
    "                num_workers=self.config.num_workers\n",
    "            )\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for img, label in tqdm(image_loader):\n",
    "                    img = img.to(self.config.device)\n",
    "                    label = label.to(self.config.device)\n",
    "                    outputs = list_models[i](img)\n",
    "\n",
    "                    propability = torch.nn.Softmax(dim = 1)(outputs)\n",
    "                    propability = propability.detach().cpu().numpy()\n",
    "                    probs_list.append(propability)\n",
    "                    preds_list.extend([np.array(self.config.classes)[np.where(prob > 1 / len(self.config.classes))] for prob in propability])\n",
    "                    \n",
    "            del model\n",
    "            probs_list = np.concatenate(probs_list)\n",
    "            preds_list = np.array(preds_list)\n",
    "            probs_dict[f\"fold_{i}\"] = probs_list\n",
    "            data[f\"fold_{i}\"] = preds_list\n",
    "            import gc\n",
    "            gc.collect()\n",
    "            \n",
    "        return probs_dict, data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "induced-casino",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-19T09:03:20.700199Z",
     "iopub.status.busy": "2021-05-19T09:03:20.699528Z",
     "iopub.status.idle": "2021-05-19T09:03:20.702207Z",
     "shell.execute_reply": "2021-05-19T09:03:20.701794Z"
    },
    "papermill": {
     "duration": 0.01912,
     "end_time": "2021-05-19T09:03:20.702309",
     "exception": false,
     "start_time": "2021-05-19T09:03:20.683189",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def f1_score(y_true, y_pred):\n",
    "    y_true = y_true.apply(lambda x: set(x.split()))\n",
    "    y_pred = y_pred.apply(lambda x: set(x.split()))\n",
    "    intersection = np.array([len(x[0] & x[1]) for x in zip(y_true, y_pred)])\n",
    "    len_y_true = y_true.apply(lambda x: len(x)).values\n",
    "    len_y_pred = y_pred.apply(lambda x: len(x)).values\n",
    "    f1 = 2 * intersection / (len_y_true + len_y_pred)\n",
    "    \n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "olive-wellington",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-19T09:03:20.729240Z",
     "iopub.status.busy": "2021-05-19T09:03:20.728580Z",
     "iopub.status.idle": "2021-05-19T09:03:20.730856Z",
     "shell.execute_reply": "2021-05-19T09:03:20.731217Z"
    },
    "papermill": {
     "duration": 0.017592,
     "end_time": "2021-05-19T09:03:20.731332",
     "exception": false,
     "start_time": "2021-05-19T09:03:20.713740",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def combine_predictions(row):\n",
    "    temp_fold = [0]\n",
    "    x = np.concatenate([row[f'fold_{i}'] for i in range(len(temp_fold))])\n",
    "\n",
    "    # values, counts = np.unique(x, return_counts=True)\n",
    "    \n",
    "    # x = [values[i] for i in range(len(values)) if counts[i] >= 3]\n",
    "    \n",
    "    return ' '.join(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "quiet-hanging",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-19T09:03:20.759217Z",
     "iopub.status.busy": "2021-05-19T09:03:20.758681Z",
     "iopub.status.idle": "2021-05-19T09:40:25.325911Z",
     "shell.execute_reply": "2021-05-19T09:40:25.326532Z"
    },
    "papermill": {
     "duration": 2224.583814,
     "end_time": "2021-05-19T09:40:25.326751",
     "exception": false,
     "start_time": "2021-05-19T09:03:20.742937",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping 77 duplicates samples\n",
      "Buidling Model Backbone for efficientnet-b4 model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1160/1160 [36:56<00:00,  1.91s/it]\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:124: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    }
   ],
   "source": [
    "session = Main_session(GET_CV, CFG)\n",
    "_, pdata = session.get_predict_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "appropriate-magazine",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-19T09:40:25.932571Z",
     "iopub.status.busy": "2021-05-19T09:40:25.931743Z",
     "iopub.status.idle": "2021-05-19T09:40:26.520053Z",
     "shell.execute_reply": "2021-05-19T09:40:26.519151Z"
    },
    "papermill": {
     "duration": 0.891508,
     "end_time": "2021-05-19T09:40:26.520226",
     "exception": false,
     "start_time": "2021-05-19T09:40:25.628718",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our final f1 cv score is 0.9431959040689841\n"
     ]
    }
   ],
   "source": [
    "if GET_CV:\n",
    "    pdata['labels'] = pdata.apply(combine_predictions, axis = 1)\n",
    "    pdata['f1'] = f1_score(pdata['origin_labels'], pdata['labels'])\n",
    "    score = pdata['f1'].mean()\n",
    "    print(f\"Our final f1 cv score is {score}\")\n",
    "    pdata[['image', 'labels']].to_csv('submission.csv', index = False)\n",
    "\n",
    "else:\n",
    "\n",
    "    pdata['labels'] = pdata.apply(combine_predictions, axis = 1)\n",
    "    pdata[['image', 'labels']].to_csv('submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "intermediate-timing",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-19T09:40:27.127395Z",
     "iopub.status.busy": "2021-05-19T09:40:27.126892Z",
     "iopub.status.idle": "2021-05-19T09:40:27.134889Z",
     "shell.execute_reply": "2021-05-19T09:40:27.135291Z"
    },
    "papermill": {
     "duration": 0.31708,
     "end_time": "2021-05-19T09:40:27.135421",
     "exception": false,
     "start_time": "2021-05-19T09:40:26.818341",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>800113bb65efe69e.jpg</td>\n",
       "      <td>complex powdery_mildew healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8002cb321f8bfcdf.jpg</td>\n",
       "      <td>complex frog_eye_leaf_spot scab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80070f7fb5e2ccaa.jpg</td>\n",
       "      <td>scab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80077517781fb94f.jpg</td>\n",
       "      <td>scab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>800cbf0ff87721f8.jpg</td>\n",
       "      <td>complex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18550</th>\n",
       "      <td>fffb900a92289a33.jpg</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18551</th>\n",
       "      <td>fffc488fa4c0e80c.jpg</td>\n",
       "      <td>scab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18552</th>\n",
       "      <td>fffc94e092a59086.jpg</td>\n",
       "      <td>rust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18553</th>\n",
       "      <td>fffe105cf6808292.jpg</td>\n",
       "      <td>scab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18554</th>\n",
       "      <td>fffe472a0001bd25.jpg</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18555 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      image                           labels\n",
       "0      800113bb65efe69e.jpg   complex powdery_mildew healthy\n",
       "1      8002cb321f8bfcdf.jpg  complex frog_eye_leaf_spot scab\n",
       "2      80070f7fb5e2ccaa.jpg                             scab\n",
       "3      80077517781fb94f.jpg                             scab\n",
       "4      800cbf0ff87721f8.jpg                          complex\n",
       "...                     ...                              ...\n",
       "18550  fffb900a92289a33.jpg                          healthy\n",
       "18551  fffc488fa4c0e80c.jpg                             scab\n",
       "18552  fffc94e092a59086.jpg                             rust\n",
       "18553  fffe105cf6808292.jpg                             scab\n",
       "18554  fffe472a0001bd25.jpg                          healthy\n",
       "\n",
       "[18555 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdata[['image', 'labels']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2240.658809,
   "end_time": "2021-05-19T09:40:29.488489",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-05-19T09:03:08.829680",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}