{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "smooth-pollution",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-08T03:08:19.715127Z",
     "iopub.status.busy": "2021-05-08T03:08:19.712955Z",
     "iopub.status.idle": "2021-05-08T03:08:24.407683Z",
     "shell.execute_reply": "2021-05-08T03:08:24.406940Z"
    },
    "papermill": {
     "duration": 4.728486,
     "end_time": "2021-05-08T03:08:24.407958",
     "exception": false,
     "start_time": "2021-05-08T03:08:19.679472",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import os\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"3\" # \"6\"\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"2\" # \"4\"\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"3\" # \"6\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "# from custom_dataloader import FastDataLoader\n",
    "\n",
    "def ShowDataGraph(data_frame):\n",
    "\n",
    "    colors = [\"Red\", \"Green\", \"Blue\", \"Orange\", \"Gold\", \"Darkseagreen\"]\n",
    "\n",
    "    len_columns = len(data_frame.columns)\n",
    "\n",
    "    columns_name = list(data_frame.columns)\n",
    "\n",
    "    fig = make_subplots(rows=len_columns//2 + 1, cols=2, subplot_titles=tuple(columns_name))\n",
    "    current_col = 1\n",
    "\n",
    "    for i in columns_name:\n",
    "        if data_frame[i].dtype == \"object\":\n",
    "            fig.add_trace(go.Bar(x=list(dict(data_frame[i].value_counts(sort=False)).keys()) ,y=list(dict(data_frame[i].value_counts(sort=False)).values()) ), row=columns_name.index(i) //2 + 1 , col=current_col)\n",
    "        \n",
    "        else:\n",
    "            fig.add_trace(go.Histogram(x=list(data_frame[i])), row=columns_name.index(i) //2 + 1 , col=current_col)\n",
    "        current_col = current_col + 1 if current_col < 2 else 1\n",
    "            \n",
    "    fig.update_layout(height=200 * len_columns// 2 , width= 900 ,title=\"Feature values\",template=\"plotly_white\", showlegend=False)\n",
    "    \n",
    "    fig.show()\n",
    "\n",
    "def showFeatureImportant(X_frame, y, target_names=[\"Dead\", \"Survived\"]):\n",
    "    x = X_frame.unique()\n",
    "    y_list = []\n",
    "    unique_list = []\n",
    "    \n",
    "    for x_value in x:\n",
    "        indexList =  X_frame.index[X_frame == x_value]\n",
    "        Target = y.loc[indexList.tolist()]\n",
    "        values, counts = np.unique(Target, return_counts=True)\n",
    "\n",
    "        if len(values) == len(target_names):\n",
    "            unique_list.append(values)\n",
    "            y_list.append(counts)\n",
    "        \n",
    "        else:\n",
    "            counts_temp = np.zeros((2,), dtype='int64')\n",
    "            counts_temp[values] = counts\n",
    "            unique_list.append(np.array([i for i in range(len(target_names))], dtype='int64'))\n",
    "            y_list.append(counts_temp)\n",
    "\n",
    "    y_show = [[y_list[i][value] for i in range(len(y_list))] for value in range(len(target_names))]\n",
    "\n",
    "    fig = go.Figure()\n",
    "    for i in range(len(target_names)):\n",
    "        fig.add_trace(go.Bar(x=x , y=y_show[i], name=target_names[i]))\n",
    "\n",
    "    fig.update_layout(barmode='stack')\n",
    "    fig.show()\n",
    "\n",
    "def showFeatureDistribute(X_frame, showing_features, y, plot_mode=2):\n",
    "    \n",
    "    y_show = y.copy()\n",
    "\n",
    "    data_show = pd.concat([X_frame, y_show], axis=1)\n",
    "\n",
    "    data_show[y.name] = [\"Yes\" if value==1 else \"No\" for value in data_show[y.name]]\n",
    "\n",
    "    if plot_mode == 2: \n",
    "        assert len(showing_features) == 2\n",
    "        fig = px.scatter(data_show, x=showing_features[0], y=showing_features[1], color=str(y.name))\n",
    "\n",
    "        fig.update_traces(marker=dict(size=12,\n",
    "                                line=dict(width=2,\n",
    "                                            color='DarkSlateGrey')),\n",
    "                    selector=dict(mode='markers'))\n",
    "        fig.update_layout(hovermode=\"x\")\n",
    "    else:\n",
    "        assert len(showing_features) == 3\n",
    "        fig = px.scatter_3d(data_show, x=showing_features[0], y=showing_features[1], z=showing_features[2], color=y.name, symbol=y.name)\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "def make_mi_score(X, y):\n",
    "    from sklearn.feature_selection import mutual_info_classif\n",
    "    X = X.copy()\n",
    "    X.dropna(axis=1, inplace=True)\n",
    "    for colname in X.select_dtypes([\"object\", \"category\"]):\n",
    "        X[colname], _ = X[colname].factorize()\n",
    "    # All discrete features should now have integer dtypes\n",
    "    discrete_features = [pd.api.types.is_integer_dtype(t) for t in X.dtypes]\n",
    "    mi_scores = mutual_info_classif(X, y, discrete_features=discrete_features, random_state=0)\n",
    "    mi_scores = pd.Series(mi_scores, name='MI Scores', index=X.columns)\n",
    "    mi_scores = mi_scores.sort_values(ascending=False)\n",
    "\n",
    "    return mi_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suburban-copper",
   "metadata": {
    "papermill": {
     "duration": 0.026896,
     "end_time": "2021-05-08T03:08:24.462838",
     "exception": false,
     "start_time": "2021-05-08T03:08:24.435942",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "yellow-prospect",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-08T03:08:24.525277Z",
     "iopub.status.busy": "2021-05-08T03:08:24.524537Z",
     "iopub.status.idle": "2021-05-08T03:08:24.538502Z",
     "shell.execute_reply": "2021-05-08T03:08:24.539579Z"
    },
    "papermill": {
     "duration": 0.049252,
     "end_time": "2021-05-08T03:08:24.539893",
     "exception": false,
     "start_time": "2021-05-08T03:08:24.490641",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this submission notebook will compute CV score, but commit notebook will not\n"
     ]
    }
   ],
   "source": [
    "# source_folder = r\"shopee-product-matching\"\n",
    "# source_folder = r\"D:\\Coding_practice\\_Data\\shopee-product-matching\"\n",
    "source_folder = r\"../input/shopee-product-matching/\"\n",
    "\n",
    "test = pd.read_csv('../input/shopee-product-matching/test.csv')\n",
    "if len(test)>3: \n",
    "    GET_CV = False\n",
    "    \n",
    "else: \n",
    "    GET_CV =True\n",
    "    print('this submission notebook will compute CV score, but commit notebook will not')\n",
    "    \n",
    "# if os.path.exists(source_folder):\n",
    "#     GET_CV = True\n",
    "    \n",
    "# else:\n",
    "#     source_folder = r\"../input/shopee-product-matching/\"\n",
    "#     GET_CV = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "prostate-patrol",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-08T03:08:24.601574Z",
     "iopub.status.busy": "2021-05-08T03:08:24.600570Z",
     "iopub.status.idle": "2021-05-08T03:08:24.604294Z",
     "shell.execute_reply": "2021-05-08T03:08:24.603673Z"
    },
    "papermill": {
     "duration": 0.035409,
     "end_time": "2021-05-08T03:08:24.604426",
     "exception": false,
     "start_time": "2021-05-08T03:08:24.569017",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if GET_CV:\n",
    "#     from scripts.function_test import set_GPU\n",
    "#     set_GPU(1,[\"2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "voluntary-handling",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-08T03:08:24.665318Z",
     "iopub.status.busy": "2021-05-08T03:08:24.664190Z",
     "iopub.status.idle": "2021-05-08T03:08:24.667768Z",
     "shell.execute_reply": "2021-05-08T03:08:24.667142Z"
    },
    "papermill": {
     "duration": 0.036209,
     "end_time": "2021-05-08T03:08:24.667922",
     "exception": false,
     "start_time": "2021-05-08T03:08:24.631713",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../input/pytorchimagemodels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "referenced-manchester",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-08T03:08:24.730671Z",
     "iopub.status.busy": "2021-05-08T03:08:24.729787Z",
     "iopub.status.idle": "2021-05-08T03:08:29.488680Z",
     "shell.execute_reply": "2021-05-08T03:08:29.487643Z"
    },
    "papermill": {
     "duration": 4.793332,
     "end_time": "2021-05-08T03:08:29.488882",
     "exception": false,
     "start_time": "2021-05-08T03:08:24.695550",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Preliminaries\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Visuals and CV2\n",
    "import cv2\n",
    "\n",
    "# albumentations for augs\n",
    "import albumentations\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "# torch\n",
    "import torch\n",
    "import timm\n",
    "import torch.nn as nn\n",
    "from torch.nn import Parameter\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\n",
    "from torch.optim import Adam, lr_scheduler\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "processed-second",
   "metadata": {
    "papermill": {
     "duration": 0.02711,
     "end_time": "2021-05-08T03:08:29.545673",
     "exception": false,
     "start_time": "2021-05-08T03:08:29.518563",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "public-visit",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-08T03:08:29.612612Z",
     "iopub.status.busy": "2021-05-08T03:08:29.611919Z",
     "iopub.status.idle": "2021-05-08T03:08:31.401331Z",
     "shell.execute_reply": "2021-05-08T03:08:31.402239Z"
    },
    "papermill": {
     "duration": 1.830115,
     "end_time": "2021-05-08T03:08:31.402503",
     "exception": false,
     "start_time": "2021-05-08T03:08:29.572388",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_split.py:668: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  iloc._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "def read_dataset():\n",
    "    if GET_CV:\n",
    "        df = pd.read_csv(os.path.join(source_folder, 'train.csv'))\n",
    "        tmp = df.groupby(['label_group'])['posting_id'].unique().to_dict()\n",
    "        df['matches'] = df['label_group'].map(tmp)\n",
    "        df['matches'] = df['matches'].apply(lambda x: ' '.join(x))\n",
    "        skf = StratifiedKFold(n_splits=5)\n",
    "        skf.get_n_splits(df['posting_id'], df['label_group'])\n",
    "        fold = 0\n",
    "        df['fold'] = 0\n",
    "        for _, test_index in skf.split(df['posting_id'], df['label_group']):\n",
    "            \n",
    "            df['fold'].iloc[test_index] = fold\n",
    "            fold += 1\n",
    "\n",
    "        df['filepath'] = df['image'].apply(lambda x: os.path.join(source_folder, 'train_images',x))\n",
    "    else:\n",
    "        df = pd.read_csv(os.path.join(source_folder, 'test.csv'))\n",
    "\n",
    "        df['filepath'] = df['image'].apply(lambda x: os.path.join(source_folder, 'test_images',x))\n",
    "\n",
    "    return df\n",
    "\n",
    "data = read_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "varied-catalog",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-08T03:08:31.467213Z",
     "iopub.status.busy": "2021-05-08T03:08:31.466126Z",
     "iopub.status.idle": "2021-05-08T03:08:31.475909Z",
     "shell.execute_reply": "2021-05-08T03:08:31.475325Z"
    },
    "papermill": {
     "duration": 0.043831,
     "end_time": "2021-05-08T03:08:31.476048",
     "exception": false,
     "start_time": "2021-05-08T03:08:31.432217",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11014\n"
     ]
    }
   ],
   "source": [
    "if GET_CV:\n",
    "    encoder = LabelEncoder()\n",
    "    data['label_group'] = encoder.fit_transform(data['label_group'])\n",
    "    print(len(data['label_group'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "clear-sociology",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-08T03:08:32.285361Z",
     "iopub.status.busy": "2021-05-08T03:08:32.284029Z",
     "iopub.status.idle": "2021-05-08T03:08:32.291447Z",
     "shell.execute_reply": "2021-05-08T03:08:32.293420Z"
    },
    "papermill": {
     "duration": 0.789086,
     "end_time": "2021-05-08T03:08:32.294034",
     "exception": false,
     "start_time": "2021-05-08T03:08:31.504948",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DIM = (300, 300)\n",
    "\n",
    "NUM_WORKERS = 4\n",
    "TRAIN_BATCH_SIZE = 16\n",
    "VALID_BATCH_SIZE = 32\n",
    "EPOCHS = 100\n",
    "SEED = 42\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "### MODEL ###\n",
    "model_name = 'efficientnet_b3' \n",
    "\n",
    "### Metric Loss and its params ###\n",
    "loss_module = 'arcface'\n",
    "s = 30.0\n",
    "m = 0.5\n",
    "ls_eps = 0.0\n",
    "easy_margin = False\n",
    "\n",
    "### Scheduler and its params ###\n",
    "scheduler_params = {\n",
    "    \"lr_start\" : 1e-5,\n",
    "    \"lr_max\" : 1e-5 * TRAIN_BATCH_SIZE,\n",
    "    \"lr_min\" : 1e-10,\n",
    "    \"lr_ramp_ep\" : 5,\n",
    "    \"lr_sus_ep\" : 0,\n",
    "    \"lr_decay\" : 0.8,    \n",
    "}\n",
    "\n",
    "### Model Params ###\n",
    "model_params = {\n",
    "    \"n_classes\": 11014,\n",
    "    'model_name': model_name,\n",
    "    'use_fc' :False,\n",
    "    'fc_dim' : 512,\n",
    "    'dropout': 0.0,\n",
    "    'loss_module': loss_module,\n",
    "    's': s,\n",
    "    'margin': m,\n",
    "    'ls_eps': ls_eps,\n",
    "    'theta_zero': 0.785,\n",
    "    'pretrained': False\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acoustic-duncan",
   "metadata": {
    "papermill": {
     "duration": 0.059956,
     "end_time": "2021-05-08T03:08:32.431368",
     "exception": false,
     "start_time": "2021-05-08T03:08:32.371412",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "behavioral-magnet",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-08T03:08:32.540792Z",
     "iopub.status.busy": "2021-05-08T03:08:32.539794Z",
     "iopub.status.idle": "2021-05-08T03:08:32.548496Z",
     "shell.execute_reply": "2021-05-08T03:08:32.549298Z"
    },
    "papermill": {
     "duration": 0.067743,
     "end_time": "2021-05-08T03:08:32.549510",
     "exception": false,
     "start_time": "2021-05-08T03:08:32.481767",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_torch(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] =str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_torch(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "advanced-atlanta",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-08T03:08:32.661715Z",
     "iopub.status.busy": "2021-05-08T03:08:32.660613Z",
     "iopub.status.idle": "2021-05-08T03:08:32.665406Z",
     "shell.execute_reply": "2021-05-08T03:08:32.666248Z"
    },
    "papermill": {
     "duration": 0.067681,
     "end_time": "2021-05-08T03:08:32.666520",
     "exception": false,
     "start_time": "2021-05-08T03:08:32.598839",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def f1_score(y_true, y_pred):\n",
    "    y_true = y_true.apply(lambda x: set(x.split()))\n",
    "    y_pred = y_pred.apply(lambda x: set(x.split()))\n",
    "    intersection = np.array([len(x[0] & x[1]) for x in zip(y_true, y_pred)])\n",
    "    len_y_true = y_true.apply(lambda x: len(x)).values\n",
    "    len_y_pred = y_pred.apply(lambda x: len(x)).values\n",
    "    f1 = 2 * intersection / (len_y_true + len_y_pred)\n",
    "    \n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "controlled-outdoors",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-08T03:08:32.788118Z",
     "iopub.status.busy": "2021-05-08T03:08:32.787078Z",
     "iopub.status.idle": "2021-05-08T03:08:32.792564Z",
     "shell.execute_reply": "2021-05-08T03:08:32.792030Z"
    },
    "papermill": {
     "duration": 0.05719,
     "end_time": "2021-05-08T03:08:32.792694",
     "exception": false,
     "start_time": "2021-05-08T03:08:32.735504",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0 \n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "completed-southwest",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-08T03:08:32.860540Z",
     "iopub.status.busy": "2021-05-08T03:08:32.859487Z",
     "iopub.status.idle": "2021-05-08T03:08:32.863073Z",
     "shell.execute_reply": "2021-05-08T03:08:32.862500Z"
    },
    "papermill": {
     "duration": 0.039733,
     "end_time": "2021-05-08T03:08:32.863208",
     "exception": false,
     "start_time": "2021-05-08T03:08:32.823475",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fetch_loss():\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "casual-quest",
   "metadata": {
    "papermill": {
     "duration": 0.029691,
     "end_time": "2021-05-08T03:08:32.923721",
     "exception": false,
     "start_time": "2021-05-08T03:08:32.894030",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "naked-mainstream",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-08T03:08:32.992567Z",
     "iopub.status.busy": "2021-05-08T03:08:32.991702Z",
     "iopub.status.idle": "2021-05-08T03:08:32.995635Z",
     "shell.execute_reply": "2021-05-08T03:08:32.996191Z"
    },
    "papermill": {
     "duration": 0.041232,
     "end_time": "2021-05-08T03:08:32.996370",
     "exception": false,
     "start_time": "2021-05-08T03:08:32.955138",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_train_transforms():\n",
    "    return albumentations.Compose(\n",
    "        [\n",
    "            albumentations.Resize(DIM[0], DIM[1], always_apply=True),\n",
    "            albumentations.HorizontalFlip(p=0.5),\n",
    "            albumentations.VerticalFlip(p=0.5),\n",
    "            albumentations.Rotate(limit=120, p=0.8),\n",
    "            albumentations.RandomBrightness(limit=(0.09, 0.6),  p=0.5),\n",
    "            albumentations.Normalize(),\n",
    "            ToTensorV2(p=1.0)\n",
    "        ]\n",
    "    )\n",
    "def get_valid_transforms():\n",
    "    \n",
    "    return albumentations.Compose(\n",
    "     [\n",
    "         albumentations.Resize(DIM[0], DIM[1], always_apply=True),\n",
    "         albumentations.Normalize(),\n",
    "         ToTensorV2(p=1.0)\n",
    "     ]   \n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "synthetic-impossible",
   "metadata": {
    "papermill": {
     "duration": 0.028741,
     "end_time": "2021-05-08T03:08:33.054708",
     "exception": false,
     "start_time": "2021-05-08T03:08:33.025967",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "supported-street",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-08T03:08:33.122938Z",
     "iopub.status.busy": "2021-05-08T03:08:33.122221Z",
     "iopub.status.idle": "2021-05-08T03:08:33.126128Z",
     "shell.execute_reply": "2021-05-08T03:08:33.125603Z"
    },
    "papermill": {
     "duration": 0.041535,
     "end_time": "2021-05-08T03:08:33.126266",
     "exception": false,
     "start_time": "2021-05-08T03:08:33.084731",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ShopeeDataset(Dataset):\n",
    "    def __init__(self, csv,  training_section=True, transforms=None, inference=False):\n",
    "\n",
    "        self.csv = csv.reset_index()\n",
    "        self.augmentations = transforms\n",
    "        self.TS = training_section\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.csv.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.csv.iloc[index]\n",
    "\n",
    "        text = row.title\n",
    "        \n",
    "        image = cv2.imread(row.filepath)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        if self.augmentations:\n",
    "            augmented = self.augmentations(image=image)\n",
    "            image = augmented['image']\n",
    "            \n",
    "        if self.TS:\n",
    "            return image, torch.tensor(row.label_group)\n",
    "        \n",
    "        else:\n",
    "            return image, torch.tensor(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "perfect-exercise",
   "metadata": {
    "papermill": {
     "duration": 0.028973,
     "end_time": "2021-05-08T03:08:33.185192",
     "exception": false,
     "start_time": "2021-05-08T03:08:33.156219",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "stock-spokesman",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-08T03:08:33.265548Z",
     "iopub.status.busy": "2021-05-08T03:08:33.264631Z",
     "iopub.status.idle": "2021-05-08T03:08:33.269432Z",
     "shell.execute_reply": "2021-05-08T03:08:33.268852Z"
    },
    "papermill": {
     "duration": 0.054396,
     "end_time": "2021-05-08T03:08:33.269562",
     "exception": false,
     "start_time": "2021-05-08T03:08:33.215166",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ShopeeNet(nn.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "                n_classes,\n",
    "                model_name ='efficientnet_b0',\n",
    "                use_fc = False,\n",
    "                fc_dim =512,\n",
    "                dropout = 0.0,\n",
    "                loss_module = 'softmax',\n",
    "                s = 30.0,\n",
    "                margin = 0.50,\n",
    "                ls_eps = 0.0,\n",
    "                theta_zero = 0.785,\n",
    "                pretrained = False\n",
    "                ):\n",
    "        super(ShopeeNet, self).__init__()\n",
    "        print(f'Buidling Model Backbone for {model_name} model.')\n",
    "\n",
    "        self.backbone = timm.create_model(model_name, pretrained=pretrained)\n",
    "        final_in_features = self.backbone.classifier.in_features\n",
    "\n",
    "        self.backbone.classifier = nn.Identity()\n",
    "        self.backbone.global_pool = nn.Identity()\n",
    "\n",
    "        self.pooling = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "        self.use_fc = use_fc\n",
    "\n",
    "        if use_fc:\n",
    "            self.dropout = nn.Dropout(p=dropout)\n",
    "            self.fc = nn.Linear(final_in_features, fc_dim)\n",
    "            self.bn = nn.BatchNorm1d(fc_dim)\n",
    "            self._init_params()\n",
    "            final_in_features = fc_dim\n",
    "\n",
    "        self.loss_module = loss_module\n",
    "        \n",
    "        if loss_module == 'arcface':\n",
    "            self.final = ArcMarginProduct(final_in_features, n_classes, s=s, m=margin, easy_margin=False, ls_eps=ls_eps)\n",
    "            \n",
    "        else:\n",
    "            self.final = nn.Linear(final_in_features, n_classes)\n",
    "\n",
    "    def _init_params(self):\n",
    "        nn.init_xavier_normal_(self.fc.weight)\n",
    "        nn.init.constant_(self.fc.bias, 0)\n",
    "        nn.init.constant_(self.bn.weight, 1)\n",
    "        nn.init.constant_(self.bn.bias, 0)\n",
    "    \n",
    "    def forward(self, x, label):\n",
    "        feature = self.extract_feat(x)\n",
    "\n",
    "        if self.loss_module in ('arcface'):\n",
    "            logits = self.final(feature, label)\n",
    "\n",
    "        else:\n",
    "            logits = self.final(feature)\n",
    "        \n",
    "        return feature, logits\n",
    "\n",
    "    def extract_feat(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        x = self.backbone(x)\n",
    "        x = self.pooling(x).view(batch_size, -1)\n",
    "\n",
    "        if self.use_fc:\n",
    "            x = self.dropout(x)\n",
    "            x = self.fc(x)\n",
    "            x = self.bn(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impossible-pathology",
   "metadata": {
    "papermill": {
     "duration": 0.030738,
     "end_time": "2021-05-08T03:08:33.330789",
     "exception": false,
     "start_time": "2021-05-08T03:08:33.300051",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Metric Learning Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "appointed-rebound",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-08T03:08:33.404453Z",
     "iopub.status.busy": "2021-05-08T03:08:33.402693Z",
     "iopub.status.idle": "2021-05-08T03:08:33.405796Z",
     "shell.execute_reply": "2021-05-08T03:08:33.406340Z"
    },
    "papermill": {
     "duration": 0.046104,
     "end_time": "2021-05-08T03:08:33.406481",
     "exception": false,
     "start_time": "2021-05-08T03:08:33.360377",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ArcMarginProduct(nn.Module):\n",
    "    def __init__(self, in_features, out_features, s=30.0, m=0.50, easy_margin=False, ls_eps=0.0):\n",
    "        \n",
    "        super(ArcMarginProduct, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        self.ls_eps = ls_eps # Label smoothing\n",
    "        self.weight = Parameter(torch.FloatTensor(out_features, in_features))\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "\n",
    "        self.easy_margin = easy_margin\n",
    "        self.cos_m = math.cos(m)\n",
    "        self.sin_m = math.sin(m)\n",
    "        self.th = math.cos(math.pi - m)\n",
    "        self.mm = math.sin(math.pi - m) * m\n",
    "\n",
    "    def forward(self, input, label):\n",
    "\n",
    "        cosine = F.linear(F.normalize(input), F.normalize(self.weight))\n",
    "        sine = torch.sqrt(1.0 - torch.pow(cosine, 2))\n",
    "        phi = cosine * self.cos_m - sine * self.sin_m\n",
    "        if self.easy_margin:\n",
    "            phi = torch.where(cosine > 0, phi, cosine)\n",
    "\n",
    "        else:\n",
    "            phi = torch.where(cosine > self.th, phi, cosine - self.mm)\n",
    "\n",
    "        one_hot = torch.zeros(cosine.size(), device='cuda')\n",
    "        one_hot.scatter_(1, label.view(-1, 1).long(), 1)\n",
    "\n",
    "        if self.ls_eps > 0:\n",
    "            one_hot =  (1 - self.ls_eps) * one_hit + self.ls_eps / self.out_features\n",
    "\n",
    "        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n",
    "        output *= self.s\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceramic-homeless",
   "metadata": {
    "papermill": {
     "duration": 0.029847,
     "end_time": "2021-05-08T03:08:33.466366",
     "exception": false,
     "start_time": "2021-05-08T03:08:33.436519",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Custom LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bored-georgia",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-08T03:08:33.540101Z",
     "iopub.status.busy": "2021-05-08T03:08:33.538836Z",
     "iopub.status.idle": "2021-05-08T03:08:33.542674Z",
     "shell.execute_reply": "2021-05-08T03:08:33.542142Z"
    },
    "papermill": {
     "duration": 0.045843,
     "end_time": "2021-05-08T03:08:33.542804",
     "exception": false,
     "start_time": "2021-05-08T03:08:33.496961",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ShopeeScheduler(_LRScheduler):\n",
    "    def __init__(self, \n",
    "                optimizer, \n",
    "                lr_start=5e-6, \n",
    "                lr_max=1e-5, \n",
    "                lr_min=1e-6, \n",
    "                lr_ramp_ep=5, \n",
    "                lr_sus_ep=0, \n",
    "                lr_decay=0.8, \n",
    "                last_epoch=-1):\n",
    "\n",
    "        self.lr_start = lr_start\n",
    "        self.lr_max = lr_max\n",
    "        self.lr_min = lr_min\n",
    "        self.lr_ramp_ep = lr_ramp_ep\n",
    "        self.lr_sus_ep = lr_sus_ep\n",
    "        self.lr_decay = lr_decay\n",
    "        super(ShopeeScheduler, self).__init__(optimizer,last_epoch)\n",
    "\n",
    "    def get_lr(self):\n",
    "        if not self._get_lr_called_within_step:\n",
    "            warings.warn(\"To get the last learning rate computed by the scheduler, \" \"please use `get_last_lr()`.\", UserWarning)\n",
    "\n",
    "        if self.last_epoch == 0:\n",
    "            self.last_epoch += 1\n",
    "\n",
    "            return [self.lr_start for _ in self.optimizer.param_groups]\n",
    "        \n",
    "        lr = self._compute_lr_from_epoch()\n",
    "        self.last_epoch += 1\n",
    "\n",
    "        return [lr for _ in self.optimizer.param_groups]\n",
    "    \n",
    "    def _get_closed_form_lr(self):\n",
    "        return self.base_lrs\n",
    "\n",
    "    def _compute_lr_from_epoch(self):\n",
    "        if self.last_epoch < self.lr_ramp_ep:\n",
    "            lr = ((self.lr_max - self.lr_start) / \n",
    "            self.lr_ramp_ep * self.last_epoch +\n",
    "            self.lr_start)\n",
    "\n",
    "        elif self.last_epoch < self.lr_ramp_ep + self.lr_sus_ep:\n",
    "            lr = self.lr_max\n",
    "        \n",
    "        else:\n",
    "            lr = ((self.lr_max - self.lr_min) * self.lr_decay ** (self.last_epoch - self.lr_ramp_ep - self.lr_sus_ep) + self.lr_min)\n",
    "\n",
    "        return lr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funny-hungarian",
   "metadata": {
    "papermill": {
     "duration": 0.029619,
     "end_time": "2021-05-08T03:08:33.602189",
     "exception": false,
     "start_time": "2021-05-08T03:08:33.572570",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "infinite-arrest",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-08T03:08:33.672468Z",
     "iopub.status.busy": "2021-05-08T03:08:33.671538Z",
     "iopub.status.idle": "2021-05-08T03:08:33.674696Z",
     "shell.execute_reply": "2021-05-08T03:08:33.675238Z"
    },
    "papermill": {
     "duration": 0.042525,
     "end_time": "2021-05-08T03:08:33.675393",
     "exception": false,
     "start_time": "2021-05-08T03:08:33.632868",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_fn(dataloader, model, criterion, optimizer, device, scheduler, epoch):\n",
    "    model.train()\n",
    "    loss_score = AverageMeter()\n",
    "\n",
    "    tk0 = tqdm(enumerate(dataloader), total = len(dataloader))\n",
    "    for bi,d in tk0:\n",
    "        \n",
    "        batch_size = d[0].shape[0]\n",
    "\n",
    "        images = d[0]\n",
    "        targets = d[1]\n",
    "\n",
    "        images = images.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        _, output = model(images, targets)\n",
    "\n",
    "        # output = model(images, targets)\n",
    "        loss = criterion(output, targets)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_score.update(loss.detach().item(), batch_size)\n",
    "        tk0.set_postfix(Train_Loss=loss_score.avg, Epoch=epoch, LR=optimizer.param_groups[0]['lr'])\n",
    "    \n",
    "    if scheduler is not None:\n",
    "        scheduler.step()\n",
    "\n",
    "    return loss_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "understanding-challenge",
   "metadata": {
    "papermill": {
     "duration": 0.030279,
     "end_time": "2021-05-08T03:08:33.736961",
     "exception": false,
     "start_time": "2021-05-08T03:08:33.706682",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "looking-respondent",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-08T03:08:33.810154Z",
     "iopub.status.busy": "2021-05-08T03:08:33.809122Z",
     "iopub.status.idle": "2021-05-08T03:08:33.812901Z",
     "shell.execute_reply": "2021-05-08T03:08:33.812200Z"
    },
    "papermill": {
     "duration": 0.045395,
     "end_time": "2021-05-08T03:08:33.813036",
     "exception": false,
     "start_time": "2021-05-08T03:08:33.767641",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def eval_fn(data_loader, model, criterion, device):\n",
    "\n",
    "    loss_score = AverageMeter()\n",
    "\n",
    "    model.eval()\n",
    "    tk0 = tqdm(enumerate(data_loader), total=len(data_loader))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for bi,d in tk0:\n",
    "            batch_size = d[0].size()[0]\n",
    "\n",
    "            images = d[0]\n",
    "            targets = d[1]\n",
    "\n",
    "            images = images.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            _, output = model(images, targets)\n",
    "            # output = model(images, targets)\n",
    "\n",
    "            loss = criterion(output, targets)\n",
    "\n",
    "            loss_score.update(loss.detach().item(), batch_size)\n",
    "            tk0.set_postfix(Eval_Loss=loss_score.avg)\n",
    "\n",
    "    return loss_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "finite-comment",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-08T03:08:33.891244Z",
     "iopub.status.busy": "2021-05-08T03:08:33.890153Z",
     "iopub.status.idle": "2021-05-08T03:08:33.894186Z",
     "shell.execute_reply": "2021-05-08T03:08:33.893615Z"
    },
    "papermill": {
     "duration": 0.050293,
     "end_time": "2021-05-08T03:08:33.894321",
     "exception": false,
     "start_time": "2021-05-08T03:08:33.844028",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run(continue_training=False):\n",
    "    list_models = [0] * len(data['fold'].unique())\n",
    "    # for i in range(len(data['fold'].unique())):\n",
    "    for i in range(1):\n",
    "        model_path = f'model_{model_name}_IMG_SIZE_{DIM[0]}_{loss_module}_f{i}.pth'\n",
    "        try:\n",
    "            log_file = open(f\"{model_path}.txt\", \"r\")\n",
    "            lineList = log_file.readlines()\n",
    "            lastLine = lineList[-1]\n",
    "\n",
    "        except:\n",
    "            log_file = open(f\"{model_path}.txt\", \"w\")\n",
    "            lastLine = \"Best_loss: 1000\"\n",
    "\n",
    "        log_file.close()\n",
    "        logs = []\n",
    "\n",
    "        train = data[data['fold']!=i].reset_index(drop=True)\n",
    "        valid = data[data['fold']==i].reset_index(drop=True)\n",
    "\n",
    "        # Defining Dataset\n",
    "        train_dataset = ShopeeDataset(\n",
    "            csv=train,\n",
    "            training_section = GET_CV,\n",
    "            transforms=get_train_transforms(),\n",
    "        )\n",
    "\n",
    "        valid_dataset = ShopeeDataset(\n",
    "            csv=valid,\n",
    "            training_section = GET_CV,\n",
    "            transforms=get_valid_transforms(),\n",
    "        )\n",
    "\n",
    "        train_loader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=TRAIN_BATCH_SIZE,\n",
    "            pin_memory=True,\n",
    "            drop_last=True,\n",
    "            num_workers=0\n",
    "        )\n",
    "        valid_loader = DataLoader(\n",
    "            valid_dataset,\n",
    "            batch_size=VALID_BATCH_SIZE,\n",
    "            shuffle=False,\n",
    "            pin_memory=True,\n",
    "            drop_last=False,\n",
    "            num_workers=0\n",
    "        )\n",
    "\n",
    "        # Defining Model for specific fold\n",
    "        list_models[i] = ShopeeNet(**model_params)\n",
    "        # model = ShopeeNet(**model_params)\n",
    "        \n",
    "        if continue_training:\n",
    "            print(f\"Loading trained weights {model_path} to model...\")\n",
    "            list_models[i].load_state_dict(torch.load(model_path))\n",
    "\n",
    "        list_models[i].to(device=device)\n",
    "\n",
    "        # Defining criterion\n",
    "        criterion = fetch_loss()\n",
    "        criterion.to(device)\n",
    "\n",
    "        optimizer = Adam(list_models[i].parameters(), lr=scheduler_params['lr_start'])\n",
    "\n",
    "        # Defining LR Scheduler\n",
    "        scheduler = ShopeeScheduler(optimizer, **scheduler_params)\n",
    "\n",
    "        # THE ENGINE LOOP\n",
    "        best_loss = float(lastLine.split(\" \")[-1])\n",
    "        for epoch in range(EPOCHS):\n",
    "            train_loss = train_fn(train_loader, list_models[i], criterion, optimizer, device, scheduler=None, epoch=epoch)\n",
    "            \n",
    "            valid_loss = eval_fn(valid_loader, list_models[i], criterion, device)\n",
    "\n",
    "            with open(f\"{model_path}.txt\", \"a\") as file:\n",
    "                file.write(f\"Epoch: {epoch} - LR: {optimizer.param_groups[0]['lr']} - Valid_loss: {valid_loss.avg}\\n\")\n",
    "\n",
    "            if valid_loss.avg < best_loss:\n",
    "                best_loss = valid_loss.avg\n",
    "                print(\"Saving model...\")\n",
    "                torch.save(list_models[i].state_dict(), model_path)\n",
    "\n",
    "        torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "stretch-ethnic",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-08T03:08:33.960174Z",
     "iopub.status.busy": "2021-05-08T03:08:33.959210Z",
     "iopub.status.idle": "2021-05-08T03:08:33.962809Z",
     "shell.execute_reply": "2021-05-08T03:08:33.962168Z"
    },
    "papermill": {
     "duration": 0.037805,
     "end_time": "2021-05-08T03:08:33.962955",
     "exception": false,
     "start_time": "2021-05-08T03:08:33.925150",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if GET_CV:\n",
    "#     run(continue_training=True)\n",
    "#     torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coordinated-salvation",
   "metadata": {
    "papermill": {
     "duration": 0.030893,
     "end_time": "2021-05-08T03:08:34.025049",
     "exception": false,
     "start_time": "2021-05-08T03:08:33.994156",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Inference part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "treated-field",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-08T03:08:34.103450Z",
     "iopub.status.busy": "2021-05-08T03:08:34.102570Z",
     "iopub.status.idle": "2021-05-08T03:08:34.107387Z",
     "shell.execute_reply": "2021-05-08T03:08:34.106755Z"
    },
    "papermill": {
     "duration": 0.051227,
     "end_time": "2021-05-08T03:08:34.107523",
     "exception": false,
     "start_time": "2021-05-08T03:08:34.056296",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_neighbors(df, embeddings, KNN = 50, image =True, threshold=0):\n",
    "    from sklearn.neighbors import NearestNeighbors\n",
    "    \n",
    "    model = NearestNeighbors(n_neighbors = KNN)\n",
    "    model.fit(embeddings)\n",
    "    distances, indices = model.kneighbors(embeddings)\n",
    "\n",
    "    if GET_CV:\n",
    "        if image:\n",
    "            thresholds = list(np.arange(2,4,0.1))\n",
    "\n",
    "        else:\n",
    "            thresholds = list(np.arange(0.1, 1, 0.1))\n",
    "\n",
    "        scores = []\n",
    "        for threshold in thresholds:\n",
    "            predictions = []\n",
    "\n",
    "            for k in range(embeddings.shape[0]):\n",
    "                idx = np.where(distances[k,] < threshold)[0]\n",
    "                ids = indices[k, idx]\n",
    "                posting_ids = ' '.join(df['posting_id'].iloc[ids].values)\n",
    "                predictions.append(posting_ids)\n",
    "\n",
    "            df['pred_matches'] = predictions\n",
    "            df['f1'] = f1_score(df['matches'], df['pred_matches'])\n",
    "            score = df['f1'].mean()\n",
    "            print(f\"F1 score for threshold {threshold} is {score}\")\n",
    "            scores.append(score)\n",
    "            \n",
    "        thresholds_scores = pd.DataFrame({'thresholds': thresholds, 'scores': scores})\n",
    "        max_score = thresholds_scores[thresholds_scores['scores'] == thresholds_scores['scores'].max()]\n",
    "        best_threshold = max_score['thresholds'].values[0]\n",
    "        best_score = max_score['scores'].values[0]\n",
    "        print(f\"Our best score is {best_score} and has a threshold {best_threshold}\")\n",
    "\n",
    "        # Use threshold\n",
    "        predictions = []\n",
    "        for k in range(embeddings.shape[0]):\n",
    "            if image:\n",
    "                idx = np.where(distances[k,] < best_threshold)[0]\n",
    "                \n",
    "            else:\n",
    "                idx = np.where(distances[k,] < 0.6)[0]\n",
    "                \n",
    "            ids = indices[k, idx]\n",
    "            posting_ids = df['posting_id'].iloc[ids].values\n",
    "            predictions.append(posting_ids)\n",
    "\n",
    "    else:\n",
    "        predictions = []\n",
    "        for k in tqdm(range(embeddings.shape[0])):\n",
    "            if image:\n",
    "                idx = np.where(distances[k,] < threshold)[0]\n",
    "\n",
    "            else:\n",
    "                idx = np.where(distances[k,] < 0.6)[0]\n",
    "\n",
    "            ids = indices[k, idx]\n",
    "            posting_ids = df['posting_id'].iloc[ids].values\n",
    "            predictions.append(posting_ids)\n",
    "\n",
    "    del model, distances, indices\n",
    "    import gc\n",
    "    gc.collect()\n",
    "    return df, predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "social-retailer",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-08T03:08:34.174436Z",
     "iopub.status.busy": "2021-05-08T03:08:34.173541Z",
     "iopub.status.idle": "2021-05-08T03:08:34.179424Z",
     "shell.execute_reply": "2021-05-08T03:08:34.178728Z"
    },
    "papermill": {
     "duration": 0.040942,
     "end_time": "2021-05-08T03:08:34.179545",
     "exception": false,
     "start_time": "2021-05-08T03:08:34.138603",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../input/trained-models/model_efficientnet_b3_IMG_SIZE_300_arcface_f0.pth\n"
     ]
    }
   ],
   "source": [
    "valid_source = r\"../input/trained-models\"\n",
    "IMG_MODEL_PATH = os.path.join(valid_source,f'model_{model_name}_IMG_SIZE_{DIM[0]}_{loss_module}_f{0}.pth')\n",
    "print(IMG_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "inclusive-collection",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-08T03:08:34.252801Z",
     "iopub.status.busy": "2021-05-08T03:08:34.250721Z",
     "iopub.status.idle": "2021-05-08T03:08:34.254117Z",
     "shell.execute_reply": "2021-05-08T03:08:34.254750Z"
    },
    "papermill": {
     "duration": 0.044057,
     "end_time": "2021-05-08T03:08:34.254938",
     "exception": false,
     "start_time": "2021-05-08T03:08:34.210881",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_image_embeddings(csv, IMG_MODEL_PATH):\n",
    "    embeds = []\n",
    "\n",
    "    model = ShopeeNet(n_classes=model_params[\"n_classes\"], model_name=model_name)\n",
    "    model.eval()\n",
    "\n",
    "    model.load_state_dict(torch.load(IMG_MODEL_PATH),strict=False)\n",
    "    model = model.to(device)\n",
    "\n",
    "    image_dataset = ShopeeDataset(csv, GET_CV,transforms=get_valid_transforms())\n",
    "    image_loader = DataLoader(\n",
    "        image_dataset,\n",
    "        batch_size=VALID_BATCH_SIZE,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "        num_workers=4\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for img, label in tqdm(image_loader):\n",
    "            img = img.to(device)\n",
    "            label = label.to(device)\n",
    "            feat, _ = model(img, label)\n",
    "            image_embeddings = feat.detach().cpu().numpy()\n",
    "            embeds.append(image_embeddings)\n",
    "\n",
    "    del model\n",
    "    image_embeddings = np.concatenate(embeds)\n",
    "    print(f\"Our image embeddings shape is {image_embeddings.shape}\")\n",
    "    del embeds\n",
    "    import gc\n",
    "    gc.collect()\n",
    "    return image_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "backed-sweet",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-08T03:08:34.324748Z",
     "iopub.status.busy": "2021-05-08T03:08:34.324067Z",
     "iopub.status.idle": "2021-05-08T04:06:00.779056Z",
     "shell.execute_reply": "2021-05-08T04:06:00.778019Z"
    },
    "papermill": {
     "duration": 3446.492987,
     "end_time": "2021-05-08T04:06:00.779219",
     "exception": false,
     "start_time": "2021-05-08T03:08:34.286232",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buidling Model Backbone for efficientnet_b3 model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1071/1071 [07:36<00:00,  2.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our image embeddings shape is (34250, 1536)\n",
      "F1 score for threshold 2.0 is 0.609019262233277\n",
      "F1 score for threshold 2.1 is 0.6130385289902952\n",
      "F1 score for threshold 2.2 is 0.6177259938754522\n",
      "F1 score for threshold 2.3000000000000003 is 0.6213242054955572\n",
      "F1 score for threshold 2.4000000000000004 is 0.6257617408952963\n",
      "F1 score for threshold 2.5000000000000004 is 0.630029987329776\n",
      "F1 score for threshold 2.6000000000000005 is 0.6348310152789112\n",
      "F1 score for threshold 2.7000000000000006 is 0.6394075017303855\n",
      "F1 score for threshold 2.8000000000000007 is 0.6442250624668971\n",
      "F1 score for threshold 2.900000000000001 is 0.6488917253024561\n",
      "F1 score for threshold 3.000000000000001 is 0.6543870146638773\n",
      "F1 score for threshold 3.100000000000001 is 0.6595233191298938\n",
      "F1 score for threshold 3.200000000000001 is 0.6653019894516679\n",
      "F1 score for threshold 3.300000000000001 is 0.6712088569719404\n",
      "F1 score for threshold 3.4000000000000012 is 0.6775169586563519\n",
      "F1 score for threshold 3.5000000000000013 is 0.6835726609183138\n",
      "F1 score for threshold 3.6000000000000014 is 0.6910136375262246\n",
      "F1 score for threshold 3.7000000000000015 is 0.6980190149029523\n",
      "F1 score for threshold 3.8000000000000016 is 0.7058812413244776\n",
      "F1 score for threshold 3.9000000000000017 is 0.7130798883792597\n",
      "Our best score is 0.7130798883792597 and has a threshold 3.9000000000000017\n",
      "Buidling Model Backbone for efficientnet_b3 model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1071/1071 [07:24<00:00,  2.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our image embeddings shape is (34250, 1536)\n",
      "F1 score for threshold 2.0 is 0.6353292206377544\n",
      "F1 score for threshold 2.1 is 0.6415143500160809\n",
      "F1 score for threshold 2.2 is 0.6477865916055056\n",
      "F1 score for threshold 2.3000000000000003 is 0.654240671398242\n",
      "F1 score for threshold 2.4000000000000004 is 0.6614916052119392\n",
      "F1 score for threshold 2.5000000000000004 is 0.6681664104132089\n",
      "F1 score for threshold 2.6000000000000005 is 0.6763266719638092\n",
      "F1 score for threshold 2.7000000000000006 is 0.6852019938975231\n",
      "F1 score for threshold 2.8000000000000007 is 0.6941522942776525\n",
      "F1 score for threshold 2.900000000000001 is 0.7043820580701836\n",
      "F1 score for threshold 3.000000000000001 is 0.7150769383722922\n",
      "F1 score for threshold 3.100000000000001 is 0.7248176004626458\n",
      "F1 score for threshold 3.200000000000001 is 0.7346675578036862\n",
      "F1 score for threshold 3.300000000000001 is 0.7420582455180176\n",
      "F1 score for threshold 3.4000000000000012 is 0.7462028932946551\n",
      "F1 score for threshold 3.5000000000000013 is 0.746193773438074\n",
      "F1 score for threshold 3.6000000000000014 is 0.7407970702991915\n",
      "F1 score for threshold 3.7000000000000015 is 0.7279020695714629\n",
      "F1 score for threshold 3.8000000000000016 is 0.7060341312661198\n",
      "F1 score for threshold 3.9000000000000017 is 0.67573357946792\n",
      "Our best score is 0.7462028932946551 and has a threshold 3.4000000000000012\n",
      "Buidling Model Backbone for efficientnet_b3 model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1071/1071 [07:28<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our image embeddings shape is (34250, 1536)\n",
      "F1 score for threshold 2.0 is 0.6397047091906934\n",
      "F1 score for threshold 2.1 is 0.6462206895015623\n",
      "F1 score for threshold 2.2 is 0.6528972233939012\n",
      "F1 score for threshold 2.3000000000000003 is 0.6609334886590831\n",
      "F1 score for threshold 2.4000000000000004 is 0.668932263363333\n",
      "F1 score for threshold 2.5000000000000004 is 0.6769231023842863\n",
      "F1 score for threshold 2.6000000000000005 is 0.685778120710857\n",
      "F1 score for threshold 2.7000000000000006 is 0.6951271003475187\n",
      "F1 score for threshold 2.8000000000000007 is 0.7048020662047124\n",
      "F1 score for threshold 2.900000000000001 is 0.7151896232527571\n",
      "F1 score for threshold 3.000000000000001 is 0.7257311873810018\n",
      "F1 score for threshold 3.100000000000001 is 0.7354632226419826\n",
      "F1 score for threshold 3.200000000000001 is 0.7427792930138477\n",
      "F1 score for threshold 3.300000000000001 is 0.7467812936242109\n",
      "F1 score for threshold 3.4000000000000012 is 0.7457931500296988\n",
      "F1 score for threshold 3.5000000000000013 is 0.7381962018017055\n",
      "F1 score for threshold 3.6000000000000014 is 0.7203087076645756\n",
      "F1 score for threshold 3.7000000000000015 is 0.6942786651658502\n",
      "F1 score for threshold 3.8000000000000016 is 0.6608613022880719\n",
      "F1 score for threshold 3.9000000000000017 is 0.6220496582253342\n",
      "Our best score is 0.7467812936242109 and has a threshold 3.300000000000001\n",
      "Buidling Model Backbone for efficientnet_b3 model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1071/1071 [07:24<00:00,  2.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our image embeddings shape is (34250, 1536)\n",
      "F1 score for threshold 2.0 is 0.6406442758540366\n",
      "F1 score for threshold 2.1 is 0.6466405207135162\n",
      "F1 score for threshold 2.2 is 0.6536557905710274\n",
      "F1 score for threshold 2.3000000000000003 is 0.6611766938346967\n",
      "F1 score for threshold 2.4000000000000004 is 0.6685771696600235\n",
      "F1 score for threshold 2.5000000000000004 is 0.6763000097956099\n",
      "F1 score for threshold 2.6000000000000005 is 0.6848827154306592\n",
      "F1 score for threshold 2.7000000000000006 is 0.6939482102676918\n",
      "F1 score for threshold 2.8000000000000007 is 0.7042931550114416\n",
      "F1 score for threshold 2.900000000000001 is 0.7145343777166704\n",
      "F1 score for threshold 3.000000000000001 is 0.725582312342795\n",
      "F1 score for threshold 3.100000000000001 is 0.7344660055504947\n",
      "F1 score for threshold 3.200000000000001 is 0.7430964508441463\n",
      "F1 score for threshold 3.300000000000001 is 0.7473905015973427\n",
      "F1 score for threshold 3.4000000000000012 is 0.7480587601944773\n",
      "F1 score for threshold 3.5000000000000013 is 0.7416557621421588\n",
      "F1 score for threshold 3.6000000000000014 is 0.726224155691638\n",
      "F1 score for threshold 3.7000000000000015 is 0.7005738505212331\n",
      "F1 score for threshold 3.8000000000000016 is 0.668225057900892\n",
      "F1 score for threshold 3.9000000000000017 is 0.6280232485696923\n",
      "Our best score is 0.7480587601944773 and has a threshold 3.4000000000000012\n",
      "Buidling Model Backbone for efficientnet_b3 model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1071/1071 [07:32<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our image embeddings shape is (34250, 1536)\n",
      "F1 score for threshold 2.0 is 0.6170502801806204\n",
      "F1 score for threshold 2.1 is 0.6212476885746206\n",
      "F1 score for threshold 2.2 is 0.6262060080283064\n",
      "F1 score for threshold 2.3000000000000003 is 0.6313537598869927\n",
      "F1 score for threshold 2.4000000000000004 is 0.636500494182872\n",
      "F1 score for threshold 2.5000000000000004 is 0.6410784141989698\n",
      "F1 score for threshold 2.6000000000000005 is 0.6460206783481862\n",
      "F1 score for threshold 2.7000000000000006 is 0.6513697955890717\n",
      "F1 score for threshold 2.8000000000000007 is 0.6574419054347113\n",
      "F1 score for threshold 2.900000000000001 is 0.6632891691947224\n",
      "F1 score for threshold 3.000000000000001 is 0.6703371079209094\n",
      "F1 score for threshold 3.100000000000001 is 0.677414260549623\n",
      "F1 score for threshold 3.200000000000001 is 0.6851762458262979\n",
      "F1 score for threshold 3.300000000000001 is 0.6937759056285572\n",
      "F1 score for threshold 3.4000000000000012 is 0.7025977404389709\n",
      "F1 score for threshold 3.5000000000000013 is 0.710611529681428\n",
      "F1 score for threshold 3.6000000000000014 is 0.7182567698832856\n",
      "F1 score for threshold 3.7000000000000015 is 0.7254017818978723\n",
      "F1 score for threshold 3.8000000000000016 is 0.7300397071842065\n",
      "F1 score for threshold 3.9000000000000017 is 0.7318361357575798\n",
      "Our best score is 0.7318361357575798 and has a threshold 3.9000000000000017\n"
     ]
    }
   ],
   "source": [
    "thresholds = [3.9, 3.4, 3.3, 3.4, 3.9]\n",
    "for i in range(5):\n",
    "    IMG_MODEL_PATH = os.path.join(valid_source,f'model_{model_name}_IMG_SIZE_{DIM[0]}_{loss_module}_f{i}.pth')\n",
    "#     IMG_MODEL_PATH = os.path.join(models_path, f'model_{model_name}_IMG_SIZE_{DIM[0]}_{loss_module}_f{0}.pth')\n",
    "    image_embeddings = get_image_embeddings(data, IMG_MODEL_PATH)\n",
    "    data, image_predictions = get_neighbors(data, image_embeddings, KNN = 50, image = True, threshold=thresholds[i])\n",
    "    data[f'image_predictions_f{i}'] = image_predictions\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "material-india",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-08T04:06:04.507908Z",
     "iopub.status.busy": "2021-05-08T04:06:04.505377Z",
     "iopub.status.idle": "2021-05-08T04:06:04.508822Z",
     "shell.execute_reply": "2021-05-08T04:06:04.509397Z"
    },
    "papermill": {
     "duration": 1.875607,
     "end_time": "2021-05-08T04:06:04.509554",
     "exception": false,
     "start_time": "2021-05-08T04:06:02.633947",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def combine_predictions(row):\n",
    "#     x = np.concatenate([row['image_predictions'], row['text_predictions']])\n",
    "#     return ' '.join( np.unique(x) )\n",
    "#     return ' '.join( np.unique(row['image_predictions']) )\n",
    "#     x = np.concatenate([row[f'image_predictions_f{i}'] for i in [0,4]])\n",
    "    x = np.concatenate([row[f'image_predictions_f{i}'] for i in range(5)])\n",
    "#     return ' '.join( np.unique(x) )\n",
    "\n",
    "    values, counts = np.unique(x, return_counts=True)\n",
    "    \n",
    "    x = [values[i] for i in range(len(values)) if counts[i] >= 3]\n",
    "    \n",
    "    return ' '.join(x)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "respected-favorite",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-08T04:06:08.519660Z",
     "iopub.status.busy": "2021-05-08T04:06:08.518494Z",
     "iopub.status.idle": "2021-05-08T04:06:12.348470Z",
     "shell.execute_reply": "2021-05-08T04:06:12.347586Z"
    },
    "papermill": {
     "duration": 5.69526,
     "end_time": "2021-05-08T04:06:12.348672",
     "exception": false,
     "start_time": "2021-05-08T04:06:06.653412",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our final f1 cv score is 0.7474572126949652\n"
     ]
    }
   ],
   "source": [
    "if GET_CV:\n",
    "#     data['image_predictions'] = image_predictions\n",
    "    # data['text_predictions'] = text_predictions\n",
    "    # data['pred_matches'] = data.apply(combine_predictions, aixs=1)\n",
    "    try:\n",
    "        data.drop(columns = [\"pred_matches\", \"f1\"], inplace=True)\n",
    "        \n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    data['pred_matches'] = data.apply(combine_predictions, axis = 1)\n",
    "    data['f1'] = f1_score(data['matches'], data['pred_matches'])\n",
    "    score = data['f1'].mean()\n",
    "    print(f\"Our final f1 cv score is {score}\")\n",
    "    data['matches'] = data['pred_matches']\n",
    "    data[['posting_id', 'matches']].to_csv('submission.csv', index = False)\n",
    "\n",
    "else:\n",
    "#     data['image_predictions'] = image_predictions\n",
    "    # data['text_predictions'] = text_predictions\n",
    "    # data['matches'] = df.apply(combine_predictions, axis = 1)\n",
    "    data['matches'] = data.apply(combine_predictions, axis = 1)\n",
    "    data[['posting_id', 'matches']].to_csv('submission.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3486.059888,
   "end_time": "2021-05-08T04:06:17.472862",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-05-08T03:08:11.412974",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
