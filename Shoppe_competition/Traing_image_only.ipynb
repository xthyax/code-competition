{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import os\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"3\" # \"6\"\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"2\" # \"4\"\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"3\" # \"6\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "# from custom_dataloader import FastDataLoader\n",
    "\n",
    "def ShowDataGraph(data_frame):\n",
    "\n",
    "    colors = [\"Red\", \"Green\", \"Blue\", \"Orange\", \"Gold\", \"Darkseagreen\"]\n",
    "\n",
    "    len_columns = len(data_frame.columns)\n",
    "\n",
    "    columns_name = list(data_frame.columns)\n",
    "\n",
    "    fig = make_subplots(rows=len_columns//2 + 1, cols=2, subplot_titles=tuple(columns_name))\n",
    "    current_col = 1\n",
    "\n",
    "    for i in columns_name:\n",
    "        if data_frame[i].dtype == \"object\":\n",
    "            fig.add_trace(go.Bar(x=list(dict(data_frame[i].value_counts(sort=False)).keys()) ,y=list(dict(data_frame[i].value_counts(sort=False)).values()) ), row=columns_name.index(i) //2 + 1 , col=current_col)\n",
    "        \n",
    "        else:\n",
    "            fig.add_trace(go.Histogram(x=list(data_frame[i])), row=columns_name.index(i) //2 + 1 , col=current_col)\n",
    "        current_col = current_col + 1 if current_col < 2 else 1\n",
    "            \n",
    "    fig.update_layout(height=200 * len_columns// 2 , width= 900 ,title=\"Feature values\",template=\"plotly_white\", showlegend=False)\n",
    "    \n",
    "    fig.show()\n",
    "\n",
    "def showFeatureImportant(X_frame, y, target_names=[\"Dead\", \"Survived\"]):\n",
    "    x = X_frame.unique()\n",
    "    y_list = []\n",
    "    unique_list = []\n",
    "    \n",
    "    for x_value in x:\n",
    "        indexList =  X_frame.index[X_frame == x_value]\n",
    "        Target = y.loc[indexList.tolist()]\n",
    "        values, counts = np.unique(Target, return_counts=True)\n",
    "\n",
    "        if len(values) == len(target_names):\n",
    "            unique_list.append(values)\n",
    "            y_list.append(counts)\n",
    "        \n",
    "        else:\n",
    "            counts_temp = np.zeros((2,), dtype='int64')\n",
    "            counts_temp[values] = counts\n",
    "            unique_list.append(np.array([i for i in range(len(target_names))], dtype='int64'))\n",
    "            y_list.append(counts_temp)\n",
    "\n",
    "    y_show = [[y_list[i][value] for i in range(len(y_list))] for value in range(len(target_names))]\n",
    "\n",
    "    fig = go.Figure()\n",
    "    for i in range(len(target_names)):\n",
    "        fig.add_trace(go.Bar(x=x , y=y_show[i], name=target_names[i]))\n",
    "\n",
    "    fig.update_layout(barmode='stack')\n",
    "    fig.show()\n",
    "\n",
    "def showFeatureDistribute(X_frame, showing_features, y, plot_mode=2):\n",
    "    \n",
    "    y_show = y.copy()\n",
    "\n",
    "    data_show = pd.concat([X_frame, y_show], axis=1)\n",
    "\n",
    "    data_show[y.name] = [\"Yes\" if value==1 else \"No\" for value in data_show[y.name]]\n",
    "\n",
    "    if plot_mode == 2: \n",
    "        assert len(showing_features) == 2\n",
    "        fig = px.scatter(data_show, x=showing_features[0], y=showing_features[1], color=str(y.name))\n",
    "\n",
    "        fig.update_traces(marker=dict(size=12,\n",
    "                                line=dict(width=2,\n",
    "                                            color='DarkSlateGrey')),\n",
    "                    selector=dict(mode='markers'))\n",
    "        fig.update_layout(hovermode=\"x\")\n",
    "    else:\n",
    "        assert len(showing_features) == 3\n",
    "        fig = px.scatter_3d(data_show, x=showing_features[0], y=showing_features[1], z=showing_features[2], color=y.name, symbol=y.name)\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "def make_mi_score(X, y):\n",
    "    from sklearn.feature_selection import mutual_info_classif\n",
    "    X = X.copy()\n",
    "    X.dropna(axis=1, inplace=True)\n",
    "    for colname in X.select_dtypes([\"object\", \"category\"]):\n",
    "        X[colname], _ = X[colname].factorize()\n",
    "    # All discrete features should now have integer dtypes\n",
    "    discrete_features = [pd.api.types.is_integer_dtype(t) for t in X.dtypes]\n",
    "    mi_scores = mutual_info_classif(X, y, discrete_features=discrete_features, random_state=0)\n",
    "    mi_scores = pd.Series(mi_scores, name='MI Scores', index=X.columns)\n",
    "    mi_scores = mi_scores.sort_values(ascending=False)\n",
    "\n",
    "    return mi_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_folder = r\"shopee-product-matching\"\n",
    "# source_folder = r\"D:\\Coding_practice\\_Data\\shopee-product-matching\"\n",
    "if os.path.exists(source_folder):\n",
    "    GET_CV = True\n",
    "    \n",
    "else:\n",
    "    source_folder = r\"../input/shopee-product-matching/\"\n",
    "    GET_CV = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[INFO] ***********************************************\n",
      "[INFO] You are using GPU(s): 2\n",
      "[INFO] ***********************************************\n"
     ]
    }
   ],
   "source": [
    "if GET_CV:\n",
    "    from scripts.function_test import set_GPU\n",
    "    set_GPU(1,[\"2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../input/pytorch-image-models/pytorch-image-models-master')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preliminaries\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Visuals and CV2\n",
    "import cv2\n",
    "\n",
    "# albumentations for augs\n",
    "import albumentations\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "# torch\n",
    "import torch\n",
    "import timm\n",
    "import torch.nn as nn\n",
    "from torch.nn import Parameter\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\n",
    "from torch.optim import Adam, lr_scheduler\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset():\n",
    "    if GET_CV:\n",
    "        df = pd.read_csv(os.path.join(source_folder, 'train.csv'))\n",
    "        tmp = df.groupby(['label_group'])['posting_id'].unique().to_dict()\n",
    "        df['matches'] = df['label_group'].map(tmp)\n",
    "        df['matches'] = df['matches'].apply(lambda x: ' '.join(x))\n",
    "        skf = StratifiedKFold(n_splits=5)\n",
    "        skf.get_n_splits(df['posting_id'], df['label_group'])\n",
    "        fold = 0\n",
    "        df['fold'] = 0\n",
    "        for _, test_index in skf.split(df['posting_id'], df['label_group']):\n",
    "            \n",
    "            df['fold'].iloc[test_index] = fold\n",
    "            fold += 1\n",
    "\n",
    "        df['filepath'] = df['image'].apply(lambda x: os.path.join(source_folder, 'train_images',x))\n",
    "    else:\n",
    "        df = pd.read_csv(os.path.join(source_folder, 'test.csv'))\n",
    "\n",
    "        df['filepath'] = df['image'].apply(lambda x: os.path.join(source_folder, 'test_images',x))\n",
    "\n",
    "    return df\n",
    "\n",
    "data = read_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "11014\n"
     ]
    }
   ],
   "source": [
    "\n",
    "encoder = LabelEncoder()\n",
    "data['label_group'] = encoder.fit_transform(data['label_group'])\n",
    "print(len(data['label_group'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIM = (300, 300)\n",
    "\n",
    "NUM_WORKERS = 4\n",
    "TRAIN_BATCH_SIZE = 16\n",
    "VALID_BATCH_SIZE = 32\n",
    "EPOCHS = 100\n",
    "SEED = 42\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "### MODEL ###\n",
    "model_name = 'efficientnet_b3' \n",
    "\n",
    "### Metric Loss and its params ###\n",
    "loss_module = 'arcface'\n",
    "s = 30.0\n",
    "m = 0.5\n",
    "ls_eps = 0.0\n",
    "easy_margin = False\n",
    "\n",
    "### Scheduler and its params ###\n",
    "scheduler_params = {\n",
    "    \"lr_start\" : 1e-5,\n",
    "    \"lr_max\" : 1e-5 * TRAIN_BATCH_SIZE,\n",
    "    \"lr_min\" : 1e-10,\n",
    "    \"lr_ramp_ep\" : 5,\n",
    "    \"lr_sus_ep\" : 0,\n",
    "    \"lr_decay\" : 0.8,    \n",
    "}\n",
    "\n",
    "### Model Params ###\n",
    "model_params = {\n",
    "    \"n_classes\": 11014,\n",
    "    'model_name': model_name,\n",
    "    'use_fc' :False,\n",
    "    'fc_dim' : 512,\n",
    "    'dropout': 0.0,\n",
    "    'loss_module': loss_module,\n",
    "    's': s,\n",
    "    'margin': m,\n",
    "    'ls_eps': ls_eps,\n",
    "    'theta_zero': 0.785,\n",
    "    'pretrained': True\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_torch(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] =str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_torch(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(y_true, y_pred):\n",
    "    y_true = y_true.apply(lambda x: set(x.split()))\n",
    "    y_pred = y_pred.apply(lambda x: set(x.split()))\n",
    "    intersection = np.array([len(x[0] & x[1]) for x in zip(y_true, y_pred)])\n",
    "    len_y_true = y_true.apply(lambda x: len(x)).values\n",
    "    len_y_pred = y_pred.apply(lambda x: len(x)).values\n",
    "    f1 = 2 * intersection / (len_y_true + len_y_pred)\n",
    "    \n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0 \n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_loss():\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_transforms():\n",
    "    return albumentations.Compose(\n",
    "        [\n",
    "            albumentations.Resize(DIM[0], DIM[1], always_apply=True),\n",
    "            albumentations.HorizontalFlip(p=0.5),\n",
    "            albumentations.VerticalFlip(p=0.5),\n",
    "            albumentations.Rotate(limit=120, p=0.8),\n",
    "            albumentations.RandomBrightness(limit=(0.09, 0.6),  p=0.5),\n",
    "            albumentations.Normalize(),\n",
    "            ToTensorV2(p=1.0)\n",
    "        ]\n",
    "    )\n",
    "def get_valid_transforms():\n",
    "    \n",
    "    return albumentations.Compose(\n",
    "     [\n",
    "         albumentations.Resize(DIM[0], DIM[1], always_apply=True),\n",
    "         albumentations.Normalize(),\n",
    "         ToTensorV2(p=1.0)\n",
    "     ]   \n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShopeeDataset(Dataset):\n",
    "    def __init__(self, csv,  transforms=None, inference=False):\n",
    "\n",
    "        self.csv = csv.reset_index()\n",
    "        self.augmentations = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.csv.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.csv.iloc[index]\n",
    "\n",
    "        text = row.title\n",
    "        \n",
    "        image = cv2.imread(row.filepath)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        if self.augmentations:\n",
    "            augmented = self.augmentations(image=image)\n",
    "            image = augmented['image']\n",
    "\n",
    "        return image, torch.tensor(row.label_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShopeeNet(nn.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "                n_classes,\n",
    "                model_name ='efficientnet_b0',\n",
    "                use_fc = False,\n",
    "                fc_dim =512,\n",
    "                dropout = 0.0,\n",
    "                loss_module = 'softmax',\n",
    "                s = 30.0,\n",
    "                margin = 0.50,\n",
    "                ls_eps = 0.0,\n",
    "                theta_zero = 0.785,\n",
    "                pretrained = True\n",
    "                ):\n",
    "        super(ShopeeNet, self).__init__()\n",
    "        print(f'Buidling Model Backbone for {model_name} model.')\n",
    "\n",
    "        self.backbone = timm.create_model(model_name, pretrained=pretrained)\n",
    "        final_in_features = self.backbone.classifier.in_features\n",
    "\n",
    "        self.backbone.classifier = nn.Identity()\n",
    "        self.backbone.global_pool = nn.Identity()\n",
    "\n",
    "        self.pooling = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "        self.use_fc = use_fc\n",
    "\n",
    "        if use_fc:\n",
    "            self.dropout = nn.Dropout(p=dropout)\n",
    "            self.fc = nn.Linear(final_in_features, fc_dim)\n",
    "            self.bn = nn.BatchNorm1d(fc_dim)\n",
    "            self._init_params()\n",
    "            final_in_features = fc_dim\n",
    "\n",
    "        self.loss_module = loss_module\n",
    "        \n",
    "        if loss_module == 'arcface':\n",
    "            self.final = ArcMarginProduct(final_in_features, n_classes, s=s, m=margin, easy_margin=False, ls_eps=ls_eps)\n",
    "            \n",
    "        else:\n",
    "            self.final = nn.Linear(final_in_features, n_classes)\n",
    "\n",
    "    def _init_params(self):\n",
    "        nn.init_xavier_normal_(self.fc.weight)\n",
    "        nn.init.constant_(self.fc.bias, 0)\n",
    "        nn.init.constant_(self.bn.weight, 1)\n",
    "        nn.init.constant_(self.bn.bias, 0)\n",
    "    \n",
    "    def forward(self, x, label):\n",
    "        feature = self.extract_feat(x)\n",
    "\n",
    "        if self.loss_module in ('arcface'):\n",
    "            logits = self.final(feature, label)\n",
    "\n",
    "        else:\n",
    "            logits = self.final(feature)\n",
    "        \n",
    "        return feature, logits\n",
    "\n",
    "    def extract_feat(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        x = self.backbone(x)\n",
    "        x = self.pooling(x).view(batch_size, -1)\n",
    "\n",
    "        if self.use_fc:\n",
    "            x = self.dropout(x)\n",
    "            x = self.fc(x)\n",
    "            x = self.bn(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metric Learning Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArcMarginProduct(nn.Module):\n",
    "    def __init__(self, in_features, out_features, s=30.0, m=0.50, easy_margin=False, ls_eps=0.0):\n",
    "        \n",
    "        super(ArcMarginProduct, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        self.ls_eps = ls_eps # Label smoothing\n",
    "        self.weight = Parameter(torch.FloatTensor(out_features, in_features))\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "\n",
    "        self.easy_margin = easy_margin\n",
    "        self.cos_m = math.cos(m)\n",
    "        self.sin_m = math.sin(m)\n",
    "        self.th = math.cos(math.pi - m)\n",
    "        self.mm = math.sin(math.pi - m) * m\n",
    "\n",
    "    def forward(self, input, label):\n",
    "\n",
    "        cosine = F.linear(F.normalize(input), F.normalize(self.weight))\n",
    "        sine = torch.sqrt(1.0 - torch.pow(cosine, 2))\n",
    "        phi = cosine * self.cos_m - sine * self.sin_m\n",
    "        if self.easy_margin:\n",
    "            phi = torch.where(cosine > 0, phi, cosine)\n",
    "\n",
    "        else:\n",
    "            phi = torch.where(cosine > self.th, phi, cosine - self.mm)\n",
    "\n",
    "        one_hot = torch.zeros(cosine.size(), device='cuda')\n",
    "        one_hot.scatter_(1, label.view(-1, 1).long(), 1)\n",
    "\n",
    "        if self.ls_eps > 0:\n",
    "            one_hot =  (1 - self.ls_eps) * one_hit + self.ls_eps / self.out_features\n",
    "\n",
    "        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n",
    "        output *= self.s\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShopeeScheduler(_LRScheduler):\n",
    "    def __init__(self, \n",
    "                optimizer, \n",
    "                lr_start=5e-6, \n",
    "                lr_max=1e-5, \n",
    "                lr_min=1e-6, \n",
    "                lr_ramp_ep=5, \n",
    "                lr_sus_ep=0, \n",
    "                lr_decay=0.8, \n",
    "                last_epoch=-1):\n",
    "\n",
    "        self.lr_start = lr_start\n",
    "        self.lr_max = lr_max\n",
    "        self.lr_min = lr_min\n",
    "        self.lr_ramp_ep = lr_ramp_ep\n",
    "        self.lr_sus_ep = lr_sus_ep\n",
    "        self.lr_decay = lr_decay\n",
    "        super(ShopeeScheduler, self).__init__(optimizer,last_epoch)\n",
    "\n",
    "    def get_lr(self):\n",
    "        if not self._get_lr_called_within_step:\n",
    "            warings.warn(\"To get the last learning rate computed by the scheduler, \" \"please use `get_last_lr()`.\", UserWarning)\n",
    "\n",
    "        if self.last_epoch == 0:\n",
    "            self.last_epoch += 1\n",
    "\n",
    "            return [self.lr_start for _ in self.optimizer.param_groups]\n",
    "        \n",
    "        lr = self._compute_lr_from_epoch()\n",
    "        self.last_epoch += 1\n",
    "\n",
    "        return [lr for _ in self.optimizer.param_groups]\n",
    "    \n",
    "    def _get_closed_form_lr(self):\n",
    "        return self.base_lrs\n",
    "\n",
    "    def _compute_lr_from_epoch(self):\n",
    "        if self.last_epoch < self.lr_ramp_ep:\n",
    "            lr = ((self.lr_max - self.lr_start) / \n",
    "            self.lr_ramp_ep * self.last_epoch +\n",
    "            self.lr_start)\n",
    "\n",
    "        elif self.last_epoch < self.lr_ramp_ep + self.lr_sus_ep:\n",
    "            lr = self.lr_max\n",
    "        \n",
    "        else:\n",
    "            lr = ((self.lr_max - self.lr_min) * self.lr_decay ** (self.last_epoch - self.lr_ramp_ep - self.lr_sus_ep) + self.lr_min)\n",
    "\n",
    "        return lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(dataloader, model, criterion, optimizer, device, scheduler, epoch):\n",
    "    model.train()\n",
    "    loss_score = AverageMeter()\n",
    "\n",
    "    tk0 = tqdm(enumerate(dataloader), total = len(dataloader))\n",
    "    for bi,d in tk0:\n",
    "        \n",
    "        batch_size = d[0].shape[0]\n",
    "\n",
    "        images = d[0]\n",
    "        targets = d[1]\n",
    "\n",
    "        images = images.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        _, output = model(images, targets)\n",
    "\n",
    "        # output = model(images, targets)\n",
    "        loss = criterion(output, targets)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_score.update(loss.detach().item(), batch_size)\n",
    "        tk0.set_postfix(Train_Loss=loss_score.avg, Epoch=epoch, LR=optimizer.param_groups[0]['lr'])\n",
    "    \n",
    "    if scheduler is not None:\n",
    "        scheduler.step()\n",
    "\n",
    "    return loss_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_fn(data_loader, model, criterion, device):\n",
    "\n",
    "    loss_score = AverageMeter()\n",
    "\n",
    "    model.eval()\n",
    "    tk0 = tqdm(enumerate(data_loader), total=len(data_loader))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for bi,d in tk0:\n",
    "            batch_size = d[0].size()[0]\n",
    "\n",
    "            images = d[0]\n",
    "            targets = d[1]\n",
    "\n",
    "            images = images.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            _, output = model(images, targets)\n",
    "            # output = model(images, targets)\n",
    "\n",
    "            loss = criterion(output, targets)\n",
    "\n",
    "            loss_score.update(loss.detach().item(), batch_size)\n",
    "            tk0.set_postfix(Eval_Loss=loss_score.avg)\n",
    "\n",
    "    return loss_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(continue_training=False):\n",
    "    list_models = [0] * len(data['fold'].unique())\n",
    "    # for i in range(len(data['fold'].unique())):\n",
    "    for i in range(1):\n",
    "        model_path = f'model_{model_name}_IMG_SIZE_{DIM[0]}_{loss_module}_f{i}.pth'\n",
    "        try:\n",
    "            log_file = open(f\"{model_path}.txt\", \"r\")\n",
    "            lineList = log_file.readlines()\n",
    "            lastLine = lineList[-1]\n",
    "\n",
    "        except:\n",
    "            log_file = open(f\"{model_path}.txt\", \"w\")\n",
    "            lastLine = \"Best_loss: 1000\"\n",
    "\n",
    "        log_file.close()\n",
    "        logs = []\n",
    "\n",
    "        train = data[data['fold']!=i].reset_index(drop=True)\n",
    "        valid = data[data['fold']==i].reset_index(drop=True)\n",
    "\n",
    "        # Defining Dataset\n",
    "        train_dataset = ShopeeDataset(\n",
    "            csv=train,\n",
    "            transforms=get_train_transforms(),\n",
    "        )\n",
    "\n",
    "        valid_dataset = ShopeeDataset(\n",
    "            csv=valid,\n",
    "            transforms=get_valid_transforms(),\n",
    "        )\n",
    "\n",
    "        train_loader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=TRAIN_BATCH_SIZE,\n",
    "            pin_memory=True,\n",
    "            drop_last=True,\n",
    "            num_workers=0\n",
    "        )\n",
    "        valid_loader = DataLoader(\n",
    "            valid_dataset,\n",
    "            batch_size=VALID_BATCH_SIZE,\n",
    "            shuffle=False,\n",
    "            pin_memory=True,\n",
    "            drop_last=False,\n",
    "            num_workers=0\n",
    "        )\n",
    "\n",
    "        # Defining Model for specific fold\n",
    "        list_models[i] = ShopeeNet(**model_params)\n",
    "        # model = ShopeeNet(**model_params)\n",
    "        \n",
    "        if continue_training:\n",
    "            print(f\"Loading trained weights {model_path} to model...\")\n",
    "            list_models[i].load_state_dict(torch.load(model_path))\n",
    "\n",
    "        list_models[i].to(device=device)\n",
    "\n",
    "        # Defining criterion\n",
    "        criterion = fetch_loss()\n",
    "        criterion.to(device)\n",
    "\n",
    "        optimizer = Adam(list_models[i].parameters(), lr=scheduler_params['lr_start'])\n",
    "\n",
    "        # Defining LR Scheduler\n",
    "        scheduler = ShopeeScheduler(optimizer, **scheduler_params)\n",
    "\n",
    "        # THE ENGINE LOOP\n",
    "        best_loss = float(lastLine.split(\" \")[-1])\n",
    "        for epoch in range(EPOCHS):\n",
    "            train_loss = train_fn(train_loader, list_models[i], criterion, optimizer, device, scheduler=None, epoch=epoch)\n",
    "            \n",
    "            valid_loss = eval_fn(valid_loader, list_models[i], criterion, device)\n",
    "\n",
    "            with open(f\"{model_path}.txt\", \"a\") as file:\n",
    "                file.write(f\"Epoch: {epoch} - LR: {optimizer.param_groups[0]['lr']} - Valid_loss: {valid_loss.avg}\\n\")\n",
    "\n",
    "            if valid_loss.avg < best_loss:\n",
    "                best_loss = valid_loss.avg\n",
    "                print(\"Saving model...\")\n",
    "                torch.save(list_models[i].state_dict(), model_path)\n",
    "\n",
    "        torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Buidling Model Backbone for efficientnet_b3 model.\n",
      "Loading trained weights model_efficientnet_b3_IMG_SIZE_300_arcface_f0.pth to model...\n",
      "  0%|          | 0/1712 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "if GET_CV:\n",
    "    run(continue_training=True)\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neighbors(df, embeddings, KNN = 50, image =True):\n",
    "    from sklearn.neighbors import NearestNeighbors\n",
    "    \n",
    "    model = NearestNeighbors(n_neighbors = KNN)\n",
    "    model.fit(embeddings)\n",
    "    distances, indices = model.kneighbors(embeddings)\n",
    "\n",
    "    if GET_CV:\n",
    "        if image:\n",
    "            thresholds = list(np.arange(2,4,0.1))\n",
    "\n",
    "        else:\n",
    "            thresholds = list(np.arange(0.1, 1, 0.1))\n",
    "\n",
    "        scores = []\n",
    "        for threshold in thresholds:\n",
    "            predictions = []\n",
    "\n",
    "            for k in range(embeddings.shape[0]):\n",
    "                idx = np.where(distances[k,] < threshold)[0]\n",
    "                ids = indices[k, idx]\n",
    "                posting_ids = ' '.join(df['posting_id'].iloc[ids].values)\n",
    "                predictions.append(posting_ids)\n",
    "\n",
    "            df['pred_matches'] = predictions\n",
    "            df['f1'] = f1_score(df['matches'], df['pred_matches'])\n",
    "            score = df['f1'].mean()\n",
    "            print(f\"F1 score for threshold {threshold} is {score}\")\n",
    "            scores.append(score)\n",
    "            \n",
    "        thresholds_scores = pd.DataFrame({'thresholds': thresholds, 'scores': scores})\n",
    "        max_score = thresholds_scores[thresholds_scores['scores'] == thresholds_scores['scores'].max()]\n",
    "        best_threshold = max_score['thresholds'].values[0]\n",
    "        best_score = max_score['scores'].values[0]\n",
    "        print(f\"Our best score is {best_score} and has a threshold {best_threshold}\")\n",
    "\n",
    "        # Use threshold\n",
    "        predictions = []\n",
    "        for k in range(embeddings.shape[0]):\n",
    "            if image:\n",
    "                idx = np.where(distances[k,] < 2.7)[0]\n",
    "            else:\n",
    "                idx = np.where(distances[k,] < 0.6)[0]\n",
    "            ids = indices[k, idx]\n",
    "            posting_ids = df['posting_id'].iloc[ids].values\n",
    "            predictions.append(posting_ids)\n",
    "\n",
    "    else:\n",
    "        predictions = []\n",
    "        for k in tqdm(range(embeddings.shape[0])):\n",
    "            if image:\n",
    "                idx = np.where(distances[k,] < 2.7)[0]\n",
    "\n",
    "            else:\n",
    "                idx = np.where(distances[k,] < 0.6)[0]\n",
    "\n",
    "            ids = indices[k, idx]\n",
    "            posting_ids = df['posting_id'].iloc[ids].values\n",
    "            predictions.append(posting_ids)\n",
    "\n",
    "    del model, distances, indices\n",
    "    import gc\n",
    "    gc.collect()\n",
    "    return df, predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "model_efficientnet_b3_IMG_SIZE_300_arcface_f0.pth\n"
     ]
    }
   ],
   "source": [
    "IMG_MODEL_PATH = f'model_{model_name}_IMG_SIZE_{DIM[0]}_{loss_module}_f{0}.pth'\n",
    "print(IMG_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_embeddings(csv):\n",
    "    embeds = []\n",
    "\n",
    "    model = ShopeeNet(n_classes=model_params[\"n_classes\"], model_name=model_name)\n",
    "    model.eval()\n",
    "\n",
    "    model.load_state_dict(torch.load(IMG_MODEL_PATH),strict=False)\n",
    "    model = model.to(device)\n",
    "\n",
    "    image_dataset = ShopeeDataset(csv, transforms=get_valid_transforms())\n",
    "    image_loader = DataLoader(\n",
    "        image_dataset,\n",
    "        batch_size=VALID_BATCH_SIZE,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "        num_workers=0\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for img, label in tqdm(image_loader):\n",
    "            img = img.to(device)\n",
    "            label = label.to(device)\n",
    "            feat, _ = model(img, label)\n",
    "            image_embeddings = feat.detach().cpu().numpy()\n",
    "            embeds.append(image_embeddings)\n",
    "\n",
    "    del model\n",
    "    image_embeddings = np.concatenate(embeds)\n",
    "    print(f\"Our image embeddings shape is {image_embeddings.shape}\")\n",
    "    del embeds\n",
    "    import gc\n",
    "    gc.collect()\n",
    "    return image_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Buidling Model Backbone for efficientnet_b3 model.\n",
      "100%|██████████| 1071/1071 [21:09<00:00,  1.19s/it]\n",
      "Our image embeddings shape is (34250, 1536)\n"
     ]
    }
   ],
   "source": [
    "image_embeddings = get_image_embeddings(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "F1 score for threshold 2.0 is 0.1198440817120977\n",
      "F1 score for threshold 2.1 is 0.11790435717236852\n",
      "F1 score for threshold 2.2 is 0.1159253710190054\n",
      "F1 score for threshold 2.3000000000000003 is 0.11447384057859793\n",
      "F1 score for threshold 2.4000000000000004 is 0.11283656134895272\n",
      "F1 score for threshold 2.5000000000000004 is 0.11147650930031622\n",
      "F1 score for threshold 2.6000000000000005 is 0.11009799142755368\n",
      "F1 score for threshold 2.7000000000000006 is 0.1087578098082553\n",
      "F1 score for threshold 2.8000000000000007 is 0.107479518841731\n",
      "F1 score for threshold 2.900000000000001 is 0.1060096818108154\n",
      "F1 score for threshold 3.000000000000001 is 0.10473351956659048\n",
      "F1 score for threshold 3.100000000000001 is 0.10361560923074195\n",
      "F1 score for threshold 3.200000000000001 is 0.10259713637711113\n",
      "F1 score for threshold 3.300000000000001 is 0.10159400415400566\n",
      "F1 score for threshold 3.4000000000000012 is 0.1006159593710583\n",
      "F1 score for threshold 3.5000000000000013 is 0.09975184326679211\n",
      "F1 score for threshold 3.6000000000000014 is 0.09895790774899206\n",
      "F1 score for threshold 3.7000000000000015 is 0.09817510962227018\n",
      "F1 score for threshold 3.8000000000000016 is 0.09750660471908726\n",
      "F1 score for threshold 3.9000000000000017 is 0.09686948243484945\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'max_scores' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-58-219a9534840e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_neighbors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_embeddings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mKNN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-57-d13bc9c011bb>\u001b[0m in \u001b[0;36mget_neighbors\u001b[1;34m(df, embeddings, KNN, image)\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mmax_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mthresholds_scores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mthresholds_scores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'scores'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mthresholds_scores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'scores'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0mbest_threshold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_score\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'thresholds'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m         \u001b[0mbest_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_scores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'scores'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Our best score is {best_score} and has a threshold {best_threshold}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'max_scores' is not defined"
     ]
    }
   ],
   "source": [
    "data, image_predictions = get_neighbors(data, image_embeddings, KNN = 50, image = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if GET_CV:\n",
    "    # data['image_predictions'] = image_predictions\n",
    "    # data['text_predictions'] = text_predictions\n",
    "    # data['pred_matches'] = data.apply(combine_predictions, aixs=1)\n",
    "    data['pred_matches'] = image_predictions\n",
    "    data['f1'] = f1_score(data['matches'], data['pred_matches'])\n",
    "    score = data['f1'].mean()\n",
    "    print(f\"Our final f1 cv score is {score}\")\n",
    "    data['matches'] = data['pred_matches']\n",
    "    data[['posting_id', 'matches']].to_csv('submission.csv', index = False)\n",
    "\n",
    "else:\n",
    "    # data['image_predictions'] = image_predictions\n",
    "    # data['text_predictions'] = text_predictions\n",
    "    # data['matches'] = df.apply(combine_predictions, axis = 1)\n",
    "    data['matches'] = image_predictions\n",
    "    data[['posting_id', 'matches']].to_csv('submission.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.0 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "a95dc2dbd7c6ae4085e57d15686fa28800c42ba3d90877f552687a7a6d5d5c07"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}