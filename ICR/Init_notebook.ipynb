{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook is base on here: https://www.kaggle.com/code/opamusora/optimized-0-06/notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The aim of this notebook is try to come with something simple:\n",
    "* No complex preprocessing\n",
    "* Simple models approach\n",
    "* Light ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder,normalize\n",
    "from sklearn.model_selection import KFold as KF, GridSearchCV, RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.ensemble import GradientBoostingClassifier,RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "import imblearn\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import xgboost\n",
    "import inspect\n",
    "from collections import defaultdict\n",
    "from tabpfn import TabPFNClassifier\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"D:\\Coding_pratice\\_Data\\kaggle\\icr-identify-age-related-conditions\"\n",
    "train = pd.read_csv(os.path.join(path, 'train.csv'))\n",
    "test = pd.read_csv(os.path.join(path, 'test.csv'))\n",
    "\n",
    "greeks = pd.read_csv(os.path.join(path, 'greeks.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_category = train.EJ.unique()[0]\n",
    "train.EJ = train.EJ.eq(first_category).astype('int')\n",
    "test.EJ = test.EJ.eq(first_category).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ID = test['Id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train.drop(['Id', 'Class'], axis=1)\n",
    "y = train['Class']\n",
    "test = test.drop(['Id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanced_log_loss(y_true, y_pred):\n",
    "    N_0 = np.sum(1 - y_true)\n",
    "    N_1 = np.sum(y_true)\n",
    "\n",
    "    w_0 = 1 / N_0\n",
    "    w_1 = 1 / N_1\n",
    "\n",
    "    p_1 = np.clip(y_pred, 1e-15, 1 - 1e-15)\n",
    "    p_0 = 1 - p_1\n",
    "\n",
    "    log_loss_0 = -np.sum((1 - y_true) * np.log(p_0))\n",
    "    log_loss_1 = -np.sum(y_true * np.log(p_1))\n",
    "\n",
    "    balanced_log_loss = 2*(w_0 * log_loss_0 + w_1 * log_loss_1) / (w_0 + w_1)\n",
    "\n",
    "    return balanced_log_loss/(N_0+N_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ensemble():\n",
    "    def __init__(self) -> None:\n",
    "        self.imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "        self.classifiers = [\n",
    "            xgboost.XGBClassifier(\n",
    "            n_estimator=100, max_depth=3, learning_rate=0.2, subsample=0.9, colsample_bytree=0.85\n",
    "            ),\n",
    "            xgboost.XGBClassifier(\n",
    "            learning_rate=0.02, n_estimators=600, objective='binary:logistic', metric='binary_logloss',\n",
    "            **{'subsample': 0.6, 'min_child_weight': 1, 'max_depth': 3, 'gamma': 1, 'colsample_bytree': 0.95}\n",
    "            ),\n",
    "            xgboost.XGBClassifier(),\n",
    "            TabPFNClassifier(N_ensemble_configurations=24),\n",
    "            TabPFNClassifier(N_ensemble_configurations=64)\n",
    "        ]\n",
    "    def fit(self, X, y):\n",
    "        X = self.imputer.fit_transform(X)\n",
    "        for cls in self.classifiers:\n",
    "            if cls == self.classifiers[-2] or cls == self.classifiers[-1]:\n",
    "                cls.fit(X, y, overwrite_warning=True)\n",
    "                \n",
    "            else:\n",
    "                cls.fit(X, y)\n",
    "\n",
    "    def predict_proba(self, x):\n",
    "        x = self.imputer.transform(x)\n",
    "        # Stack ensemble models result\n",
    "        probabilites = np.stack(\n",
    "            [cls.predict_proba(x) for cls in self.classifiers]\n",
    "        )\n",
    "        # Average prediction result across all classifier\n",
    "        avg_probabilites = np.mean(probabilites, axis=0)\n",
    "\n",
    "        # Calculate the sum of the average predicted probabilities for class 0\n",
    "        # Calculate the sum of the average predicted probabilities for other class\n",
    "        class_0_est_instances = avg_probabilites[:, 0].sum()\n",
    "        others_est_instances = len(avg_probabilites) - class_0_est_instances\n",
    "        \n",
    "        # Weight the average by class\n",
    "        new_probabilites = avg_probabilites * np.array([\n",
    "            [1 / (class_0_est_instances if i==0 else others_est_instances) for i in range(avg_probabilites.shape[1])]\n",
    "            ])\n",
    "        \n",
    "        # Normalizes the new predicted probabilities so that they sum to 1 along the second axis \n",
    "        return new_probabilites / np.sum(new_probabilites, axis=1, keepdims=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(model, x, y, y_meta):\n",
    "    outer_results = list()\n",
    "    best_loss = np.inf\n",
    "\n",
    "    split = 0\n",
    "    splits = 5\n",
    "    \n",
    "    cv_inner = KF(n_splits=splits, shuffle=True, random_state=42)\n",
    "\n",
    "    for train_idx, val_idx in tqdm(cv_inner.split(x), total=splits):\n",
    "        split += 1\n",
    "\n",
    "        x_train, x_val = x.iloc[train_idx], x.iloc[val_idx]\n",
    "        y_train, y_val = y_meta[train_idx], y.iloc[val_idx]\n",
    "\n",
    "        model.fit(x_train, y_train)\n",
    "\n",
    "        y_pred = model.predict_proba(x_val)\n",
    "\n",
    "        p0 = y_pred[:,0]\n",
    "        p0 = np.where(p0 >0.5, 0, 1)\n",
    "        p0 = p0.reshape(len(p0))\n",
    "\n",
    "        loss = balanced_log_loss(y_val, p0)\n",
    "        \n",
    "        if loss < best_loss:\n",
    "            best_model = model\n",
    "            best_loss = loss\n",
    "        outer_results.append(loss)\n",
    "        print(\"-val_loss=%.5f, split=%.1f\" % (loss, split))\n",
    "        \n",
    "    print('LOSS: %.5f' % (np.mean(outer_results)))\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "times = greeks.Epsilon.copy()\n",
    "times[greeks.Epsilon != 'Unknown'] = greeks.Epsilon[greeks.Epsilon != 'Unknown'].map(lambda x: datetime.strptime(x,'%m/%d/%Y').toordinal())\n",
    "times[greeks.Epsilon == 'Unknown'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Epsilon']=times\n",
    "test['Epsilon']=max(times)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "ros = RandomOverSampler(random_state=42)\n",
    "train_ros, y_ros = ros.fit_resample(train, greeks.Alpha)\n",
    "\n",
    "# y_ros = [B, A, A] -> y_ros = [1, 0, 0]\n",
    "# Return label as index\n",
    "_, y_ros = np.unique(y_ros, return_inverse=True)\n",
    "\n",
    "x_ros = train_ros.drop(['Class', 'Id'], axis=1)\n",
    "y_ = train_ros.Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply grid search for better hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[17:23:04] WARNING: C:\\Users\\dev-admin\\croot2\\xgboost-split_1675461376218\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"metric\", \"silent\" } are not used.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=&lt;generator object _BaseKFold.split at 0x000002759A76B200&gt;,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=False,\n",
       "                                           eval_metric=None, feature_types=None,\n",
       "                                           gamma=None, gpu_id=None,\n",
       "                                           grow_policy=None,\n",
       "                                           importance_...\n",
       "                                           monotone_constraints=None,\n",
       "                                           n_estimators=600, n_jobs=None,\n",
       "                                           nthread=1, num_parallel_tree=None, ...),\n",
       "                   n_iter=20, n_jobs=2,\n",
       "                   param_distributions={&#x27;colsample_bytree&#x27;: [0.6, 0.8, 0.95,\n",
       "                                                             1.0],\n",
       "                                        &#x27;gamma&#x27;: [0.5, 1, 1.5, 2, 5],\n",
       "                                        &#x27;max_depth&#x27;: [3, 4, 5],\n",
       "                                        &#x27;min_child_weight&#x27;: [1, 5, 10],\n",
       "                                        &#x27;subsample&#x27;: [0.6, 0.8, 1.0]},\n",
       "                   random_state=42,\n",
       "                   scoring=make_scorer(balanced_log_loss, greater_is_better=False),\n",
       "                   verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=&lt;generator object _BaseKFold.split at 0x000002759A76B200&gt;,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=False,\n",
       "                                           eval_metric=None, feature_types=None,\n",
       "                                           gamma=None, gpu_id=None,\n",
       "                                           grow_policy=None,\n",
       "                                           importance_...\n",
       "                                           monotone_constraints=None,\n",
       "                                           n_estimators=600, n_jobs=None,\n",
       "                                           nthread=1, num_parallel_tree=None, ...),\n",
       "                   n_iter=20, n_jobs=2,\n",
       "                   param_distributions={&#x27;colsample_bytree&#x27;: [0.6, 0.8, 0.95,\n",
       "                                                             1.0],\n",
       "                                        &#x27;gamma&#x27;: [0.5, 1, 1.5, 2, 5],\n",
       "                                        &#x27;max_depth&#x27;: [3, 4, 5],\n",
       "                                        &#x27;min_child_weight&#x27;: [1, 5, 10],\n",
       "                                        &#x27;subsample&#x27;: [0.6, 0.8, 1.0]},\n",
       "                   random_state=42,\n",
       "                   scoring=make_scorer(balanced_log_loss, greater_is_better=False),\n",
       "                   verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.02, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              metric=&#x27;binary_logloss&#x27;, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, n_estimators=600, n_jobs=None,\n",
       "              nthread=1, num_parallel_tree=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.02, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              metric=&#x27;binary_logloss&#x27;, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, n_estimators=600, n_jobs=None,\n",
       "              nthread=1, num_parallel_tree=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=<generator object _BaseKFold.split at 0x000002759A76B200>,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=False,\n",
       "                                           eval_metric=None, feature_types=None,\n",
       "                                           gamma=None, gpu_id=None,\n",
       "                                           grow_policy=None,\n",
       "                                           importance_...\n",
       "                                           monotone_constraints=None,\n",
       "                                           n_estimators=600, n_jobs=None,\n",
       "                                           nthread=1, num_parallel_tree=None, ...),\n",
       "                   n_iter=20, n_jobs=2,\n",
       "                   param_distributions={'colsample_bytree': [0.6, 0.8, 0.95,\n",
       "                                                             1.0],\n",
       "                                        'gamma': [0.5, 1, 1.5, 2, 5],\n",
       "                                        'max_depth': [3, 4, 5],\n",
       "                                        'min_child_weight': [1, 5, 10],\n",
       "                                        'subsample': [0.6, 0.8, 1.0]},\n",
       "                   random_state=42,\n",
       "                   scoring=make_scorer(balanced_log_loss, greater_is_better=False),\n",
       "                   verbose=3)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "xgb_params = {\n",
    "    'min_child_weight': [1, 5, 10],\n",
    "    'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 0.95, 1.0],\n",
    "    'max_depth': [3, 4, 5]\n",
    "}\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "x_cv = imputer.fit_transform(x_ros)\n",
    "\n",
    "xgb = xgboost.XGBClassifier(\n",
    "    learning_rate=0.02, n_estimators=600, objective='binary:logistic', silent=True, nthread=1 , metric='binary_logloss'\n",
    ")\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "score = make_scorer(balanced_log_loss, greater_is_better=False)\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    xgb, param_distributions=xgb_params, n_iter=20, scoring=score, n_jobs=2, \n",
    "    cv=skf.split(x_cv, y_), random_state=42,\n",
    "    verbose=3\n",
    "    )\n",
    "\n",
    "# random_search = GridSearchCV(\n",
    "#     xgb, param_grid=xgb_params, scoring=score, n_jobs=2, \n",
    "#     cv=skf.split(x_cv, y_),\n",
    "#     verbose=3\n",
    "#     )\n",
    "random_search.fit(x_cv, y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " All results:\n",
      "{'mean_fit_time': array([1.45554199, 1.59349203, 1.27301722, 0.88631902, 2.02568493,\n",
      "       1.17601762, 1.57514381, 1.67340302, 2.38397698, 1.33075767,\n",
      "       0.94937258, 1.42465711, 1.31600981, 1.27266021, 1.4069222 ,\n",
      "       1.17036462, 1.22766113, 1.53541064, 1.83969312, 1.04156213]), 'std_fit_time': array([0.01229441, 0.02282668, 0.00941383, 0.00715819, 0.00604695,\n",
      "       0.02489672, 0.0064445 , 0.01690978, 0.0122939 , 0.05510515,\n",
      "       0.01168762, 0.00985123, 0.00882701, 0.02657337, 0.01348203,\n",
      "       0.00995311, 0.00945775, 0.00843473, 0.01626224, 0.00590992]), 'mean_score_time': array([0.00458488, 0.00479136, 0.00299025, 0.00419326, 0.00398731,\n",
      "       0.00518317, 0.00438628, 0.00478477, 0.00438604, 0.00318227,\n",
      "       0.00419374, 0.00338893, 0.00358882, 0.00558214, 0.00358849,\n",
      "       0.00418634, 0.00332689, 0.00438538, 0.00418615, 0.00398669]), 'std_score_time': array([7.97498431e-04, 7.57837111e-04, 3.98950589e-07, 9.90106085e-04,\n",
      "       6.39744180e-07, 3.98898221e-04, 4.89027986e-04, 7.45639542e-04,\n",
      "       4.88052058e-04, 3.84402493e-04, 4.14037855e-04, 4.88674980e-04,\n",
      "       4.88247130e-04, 4.88851571e-04, 4.88266474e-04, 3.98421384e-04,\n",
      "       4.23410695e-04, 4.87915886e-04, 3.98874411e-04, 6.30449823e-04]), 'param_subsample': masked_array(data=[0.8, 0.8, 1.0, 1.0, 0.8, 1.0, 0.6, 0.8, 0.6, 1.0, 0.6,\n",
      "                   0.6, 1.0, 0.6, 1.0, 0.6, 1.0, 1.0, 0.8, 0.8],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_min_child_weight': masked_array(data=[5, 1, 10, 5, 1, 5, 1, 5, 1, 5, 10, 1, 5, 5, 1, 10, 10,\n",
      "                   1, 5, 1],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_max_depth': masked_array(data=[4, 5, 3, 3, 4, 5, 3, 4, 5, 3, 3, 4, 3, 5, 3, 3, 3, 5,\n",
      "                   4, 3],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_gamma': masked_array(data=[2, 1.5, 5, 2, 1.5, 1.5, 1, 0.5, 1.5, 5, 0.5, 5, 0.5,\n",
      "                   1.5, 0.5, 1.5, 2, 2, 5, 1.5],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_colsample_bytree': masked_array(data=[0.8, 0.6, 1.0, 0.6, 1.0, 0.6, 0.95, 1.0, 0.95, 0.95,\n",
      "                   0.6, 0.6, 1.0, 0.6, 0.95, 0.8, 1.0, 0.6, 1.0, 0.6],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'subsample': 0.8, 'min_child_weight': 5, 'max_depth': 4, 'gamma': 2, 'colsample_bytree': 0.8}, {'subsample': 0.8, 'min_child_weight': 1, 'max_depth': 5, 'gamma': 1.5, 'colsample_bytree': 0.6}, {'subsample': 1.0, 'min_child_weight': 10, 'max_depth': 3, 'gamma': 5, 'colsample_bytree': 1.0}, {'subsample': 1.0, 'min_child_weight': 5, 'max_depth': 3, 'gamma': 2, 'colsample_bytree': 0.6}, {'subsample': 0.8, 'min_child_weight': 1, 'max_depth': 4, 'gamma': 1.5, 'colsample_bytree': 1.0}, {'subsample': 1.0, 'min_child_weight': 5, 'max_depth': 5, 'gamma': 1.5, 'colsample_bytree': 0.6}, {'subsample': 0.6, 'min_child_weight': 1, 'max_depth': 3, 'gamma': 1, 'colsample_bytree': 0.95}, {'subsample': 0.8, 'min_child_weight': 5, 'max_depth': 4, 'gamma': 0.5, 'colsample_bytree': 1.0}, {'subsample': 0.6, 'min_child_weight': 1, 'max_depth': 5, 'gamma': 1.5, 'colsample_bytree': 0.95}, {'subsample': 1.0, 'min_child_weight': 5, 'max_depth': 3, 'gamma': 5, 'colsample_bytree': 0.95}, {'subsample': 0.6, 'min_child_weight': 10, 'max_depth': 3, 'gamma': 0.5, 'colsample_bytree': 0.6}, {'subsample': 0.6, 'min_child_weight': 1, 'max_depth': 4, 'gamma': 5, 'colsample_bytree': 0.6}, {'subsample': 1.0, 'min_child_weight': 5, 'max_depth': 3, 'gamma': 0.5, 'colsample_bytree': 1.0}, {'subsample': 0.6, 'min_child_weight': 5, 'max_depth': 5, 'gamma': 1.5, 'colsample_bytree': 0.6}, {'subsample': 1.0, 'min_child_weight': 1, 'max_depth': 3, 'gamma': 0.5, 'colsample_bytree': 0.95}, {'subsample': 0.6, 'min_child_weight': 10, 'max_depth': 3, 'gamma': 1.5, 'colsample_bytree': 0.8}, {'subsample': 1.0, 'min_child_weight': 10, 'max_depth': 3, 'gamma': 2, 'colsample_bytree': 1.0}, {'subsample': 1.0, 'min_child_weight': 1, 'max_depth': 5, 'gamma': 2, 'colsample_bytree': 0.6}, {'subsample': 0.8, 'min_child_weight': 5, 'max_depth': 4, 'gamma': 5, 'colsample_bytree': 1.0}, {'subsample': 0.8, 'min_child_weight': 1, 'max_depth': 3, 'gamma': 1.5, 'colsample_bytree': 0.6}], 'split0_test_score': array([-0.76190241, -0.76190241, -1.01586988, -0.63491868, -0.88888615,\n",
      "       -0.50793494, -0.50793494, -0.63491868, -0.76190241, -1.01586988,\n",
      "       -1.39682109, -1.14285362, -0.63491868, -1.01586988, -0.63491868,\n",
      "       -1.26983735, -1.01586988, -0.63491868, -0.76190241, -0.50793494]), 'split1_test_score': array([-0.3828255, -0.255217 , -0.8932595, -0.6380425, -0.3828255,\n",
      "       -0.3828255, -0.3828255, -0.3828255, -0.3828255, -0.765651 ,\n",
      "       -0.6380425, -0.510434 , -0.510434 , -0.255217 , -0.255217 ,\n",
      "       -0.6380425, -0.6380425, -0.255217 , -0.765651 , -0.3828255]), 'split2_test_score': array([-0.6359574 , -0.6359574 , -1.01753183, -0.76314888, -0.76314888,\n",
      "       -0.76314888, -0.50876592, -0.6359574 , -0.6359574 , -0.89034036,\n",
      "       -1.27191479, -1.14472331, -0.76314888, -0.89034036, -0.76314888,\n",
      "       -1.27191479, -0.76314888, -0.38157444, -0.76314888, -0.6359574 ]), 'split3_test_score': array([-0.38157444, -0.38157444, -0.89034036, -0.38157444, -0.38157444,\n",
      "       -0.38157444, -0.38157444, -0.38157444, -0.50876592, -0.50876592,\n",
      "       -0.50876592, -0.50876592, -0.38157444, -0.38157444, -0.38157444,\n",
      "       -0.38157444, -0.50876592, -0.38157444, -0.6359574 , -0.38157444]), 'split4_test_score': array([-1.65348923, -1.52629775, -2.16225515, -1.52629775, -1.65348923,\n",
      "       -1.90787219, -1.52629775, -1.52629775, -1.78068071, -2.03506367,\n",
      "       -2.16225515, -2.28944663, -1.65348923, -1.78068071, -1.52629775,\n",
      "       -2.28944663, -1.90787219, -1.90787219, -2.03506367, -1.52629775]), 'mean_test_score': array([-0.7631498 , -0.7121898 , -1.19585134, -0.78879645, -0.81398484,\n",
      "       -0.78867119, -0.66147971, -0.71231475, -0.81402639, -1.04313817,\n",
      "       -1.19555989, -1.1192447 , -0.78871304, -0.86473648, -0.71223135,\n",
      "       -1.17016314, -0.96673987, -0.71223135, -0.99234467, -0.68691801]), 'std_test_score': array([0.46885607, 0.44478874, 0.48642086, 0.38905035, 0.46601272,\n",
      "       0.57663049, 0.43607405, 0.42245503, 0.49959268, 0.52355702,\n",
      "       0.59385983, 0.65021749, 0.45063181, 0.54173984, 0.4448528 ,\n",
      "       0.66001642, 0.49947476, 0.61042024, 0.52369823, 0.43009237]), 'rank_test_score': array([ 7,  3, 20, 10, 11,  8,  1,  6, 12, 16, 19, 17,  9, 13,  4, 18, 14,\n",
      "        4, 15,  2])}\n",
      "\n",
      " Best estimator:\n",
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=0.95, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=1, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.02, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
      "              metric='binary_logloss', min_child_weight=1, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=600, n_jobs=None,\n",
      "              nthread=1, num_parallel_tree=None, ...)\n",
      "\n",
      " Best hyperparameters:\n",
      "{'subsample': 0.6, 'min_child_weight': 1, 'max_depth': 3, 'gamma': 1, 'colsample_bytree': 0.95}\n"
     ]
    }
   ],
   "source": [
    "print('\\n All results:')\n",
    "print(random_search.cv_results_)\n",
    "print('\\n Best estimator:')\n",
    "print(random_search.best_estimator_)\n",
    "print('\\n Best hyperparameters:')\n",
    "print(random_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    }
   ],
   "source": [
    "ensemble_model = Ensemble()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d9f4d655cdc4795bad332a534185a77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:43:21] WARNING: C:\\Users\\dev-admin\\croot2\\xgboost-split_1675461376218\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"n_estimator\" } are not used.\n",
      "\n",
      "[17:43:21] WARNING: C:\\Users\\dev-admin\\croot2\\xgboost-split_1675461376218\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"metric\" } are not used.\n",
      "\n",
      "-val_loss=0.12283, split=1.0\n",
      "[17:44:55] WARNING: C:\\Users\\dev-admin\\croot2\\xgboost-split_1675461376218\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"n_estimator\" } are not used.\n",
      "\n",
      "[17:44:56] WARNING: C:\\Users\\dev-admin\\croot2\\xgboost-split_1675461376218\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"metric\" } are not used.\n",
      "\n",
      "-val_loss=0.00000, split=2.0\n",
      "[17:46:31] WARNING: C:\\Users\\dev-admin\\croot2\\xgboost-split_1675461376218\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"n_estimator\" } are not used.\n",
      "\n",
      "[17:46:31] WARNING: C:\\Users\\dev-admin\\croot2\\xgboost-split_1675461376218\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"metric\" } are not used.\n",
      "\n",
      "-val_loss=0.00000, split=3.0\n",
      "[17:48:05] WARNING: C:\\Users\\dev-admin\\croot2\\xgboost-split_1675461376218\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"n_estimator\" } are not used.\n",
      "\n",
      "[17:48:05] WARNING: C:\\Users\\dev-admin\\croot2\\xgboost-split_1675461376218\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"metric\" } are not used.\n",
      "\n",
      "-val_loss=0.00000, split=4.0\n",
      "[17:49:40] WARNING: C:\\Users\\dev-admin\\croot2\\xgboost-split_1675461376218\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"n_estimator\" } are not used.\n",
      "\n",
      "[17:49:40] WARNING: C:\\Users\\dev-admin\\croot2\\xgboost-split_1675461376218\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"metric\" } are not used.\n",
      "\n",
      "-val_loss=0.13386, split=5.0\n",
      "LOSS: 0.05134\n"
     ]
    }
   ],
   "source": [
    "m = training(ensemble_model, x_ros, y_, y_ros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AB</th>\n",
       "      <th>AF</th>\n",
       "      <th>AH</th>\n",
       "      <th>AM</th>\n",
       "      <th>AR</th>\n",
       "      <th>AX</th>\n",
       "      <th>AY</th>\n",
       "      <th>AZ</th>\n",
       "      <th>BC</th>\n",
       "      <th>BD</th>\n",
       "      <th>...</th>\n",
       "      <th>FL</th>\n",
       "      <th>FR</th>\n",
       "      <th>FS</th>\n",
       "      <th>GB</th>\n",
       "      <th>GE</th>\n",
       "      <th>GF</th>\n",
       "      <th>GH</th>\n",
       "      <th>GI</th>\n",
       "      <th>GL</th>\n",
       "      <th>Epsilon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.209377</td>\n",
       "      <td>3109.03329</td>\n",
       "      <td>85.200147</td>\n",
       "      <td>22.394407</td>\n",
       "      <td>8.138688</td>\n",
       "      <td>0.699861</td>\n",
       "      <td>0.025578</td>\n",
       "      <td>9.812214</td>\n",
       "      <td>5.555634</td>\n",
       "      <td>4126.58731</td>\n",
       "      <td>...</td>\n",
       "      <td>7.298162</td>\n",
       "      <td>1.73855</td>\n",
       "      <td>0.094822</td>\n",
       "      <td>11.339138</td>\n",
       "      <td>72.611063</td>\n",
       "      <td>2003.810319</td>\n",
       "      <td>22.136229</td>\n",
       "      <td>69.834944</td>\n",
       "      <td>0.120343</td>\n",
       "      <td>737137.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.145282</td>\n",
       "      <td>978.76416</td>\n",
       "      <td>85.200147</td>\n",
       "      <td>36.968889</td>\n",
       "      <td>8.138688</td>\n",
       "      <td>3.632190</td>\n",
       "      <td>0.025578</td>\n",
       "      <td>13.517790</td>\n",
       "      <td>1.229900</td>\n",
       "      <td>5496.92824</td>\n",
       "      <td>...</td>\n",
       "      <td>0.173229</td>\n",
       "      <td>0.49706</td>\n",
       "      <td>0.568932</td>\n",
       "      <td>9.292698</td>\n",
       "      <td>72.611063</td>\n",
       "      <td>27981.562750</td>\n",
       "      <td>29.135430</td>\n",
       "      <td>32.131996</td>\n",
       "      <td>21.978000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.470030</td>\n",
       "      <td>2635.10654</td>\n",
       "      <td>85.200147</td>\n",
       "      <td>32.360553</td>\n",
       "      <td>8.138688</td>\n",
       "      <td>6.732840</td>\n",
       "      <td>0.025578</td>\n",
       "      <td>12.824570</td>\n",
       "      <td>1.229900</td>\n",
       "      <td>5135.78024</td>\n",
       "      <td>...</td>\n",
       "      <td>7.709560</td>\n",
       "      <td>0.97556</td>\n",
       "      <td>1.198821</td>\n",
       "      <td>37.077772</td>\n",
       "      <td>88.609437</td>\n",
       "      <td>13676.957810</td>\n",
       "      <td>28.022851</td>\n",
       "      <td>35.192676</td>\n",
       "      <td>0.196941</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.252107</td>\n",
       "      <td>3819.65177</td>\n",
       "      <td>120.201618</td>\n",
       "      <td>77.112203</td>\n",
       "      <td>8.138688</td>\n",
       "      <td>3.685344</td>\n",
       "      <td>0.025578</td>\n",
       "      <td>11.053708</td>\n",
       "      <td>1.229900</td>\n",
       "      <td>4169.67738</td>\n",
       "      <td>...</td>\n",
       "      <td>6.122162</td>\n",
       "      <td>0.49706</td>\n",
       "      <td>0.284466</td>\n",
       "      <td>18.529584</td>\n",
       "      <td>82.416803</td>\n",
       "      <td>2094.262452</td>\n",
       "      <td>39.948656</td>\n",
       "      <td>90.493248</td>\n",
       "      <td>0.155829</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.380297</td>\n",
       "      <td>3733.04844</td>\n",
       "      <td>85.200147</td>\n",
       "      <td>14.103738</td>\n",
       "      <td>8.138688</td>\n",
       "      <td>3.942255</td>\n",
       "      <td>0.054810</td>\n",
       "      <td>3.396778</td>\n",
       "      <td>102.151980</td>\n",
       "      <td>5728.73412</td>\n",
       "      <td>...</td>\n",
       "      <td>8.153058</td>\n",
       "      <td>48.50134</td>\n",
       "      <td>0.121914</td>\n",
       "      <td>16.408728</td>\n",
       "      <td>146.109943</td>\n",
       "      <td>8524.370502</td>\n",
       "      <td>45.381316</td>\n",
       "      <td>36.262628</td>\n",
       "      <td>0.096614</td>\n",
       "      <td>737509.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>0.149555</td>\n",
       "      <td>3130.05946</td>\n",
       "      <td>123.763599</td>\n",
       "      <td>9.513984</td>\n",
       "      <td>13.020852</td>\n",
       "      <td>3.499305</td>\n",
       "      <td>0.077343</td>\n",
       "      <td>8.545512</td>\n",
       "      <td>2.804172</td>\n",
       "      <td>4157.68439</td>\n",
       "      <td>...</td>\n",
       "      <td>0.173229</td>\n",
       "      <td>1.26092</td>\n",
       "      <td>0.067730</td>\n",
       "      <td>8.967128</td>\n",
       "      <td>217.148554</td>\n",
       "      <td>8095.932828</td>\n",
       "      <td>24.640462</td>\n",
       "      <td>69.191944</td>\n",
       "      <td>21.978000</td>\n",
       "      <td>737681.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>0.435846</td>\n",
       "      <td>5462.03438</td>\n",
       "      <td>85.200147</td>\n",
       "      <td>46.551007</td>\n",
       "      <td>15.973224</td>\n",
       "      <td>5.979825</td>\n",
       "      <td>0.025882</td>\n",
       "      <td>12.622906</td>\n",
       "      <td>3.777550</td>\n",
       "      <td>5654.07556</td>\n",
       "      <td>...</td>\n",
       "      <td>10.223150</td>\n",
       "      <td>1.24236</td>\n",
       "      <td>0.426699</td>\n",
       "      <td>35.896418</td>\n",
       "      <td>496.994214</td>\n",
       "      <td>3085.308063</td>\n",
       "      <td>29.648928</td>\n",
       "      <td>124.808872</td>\n",
       "      <td>0.145340</td>\n",
       "      <td>737676.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>0.427300</td>\n",
       "      <td>2459.10720</td>\n",
       "      <td>130.138587</td>\n",
       "      <td>55.355778</td>\n",
       "      <td>10.005552</td>\n",
       "      <td>8.070549</td>\n",
       "      <td>0.025578</td>\n",
       "      <td>15.408390</td>\n",
       "      <td>1.229900</td>\n",
       "      <td>5888.87769</td>\n",
       "      <td>...</td>\n",
       "      <td>0.173229</td>\n",
       "      <td>0.49706</td>\n",
       "      <td>0.067730</td>\n",
       "      <td>19.962092</td>\n",
       "      <td>128.896894</td>\n",
       "      <td>6474.652866</td>\n",
       "      <td>26.166072</td>\n",
       "      <td>119.559420</td>\n",
       "      <td>21.978000</td>\n",
       "      <td>737264.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>0.363205</td>\n",
       "      <td>1263.53524</td>\n",
       "      <td>85.200147</td>\n",
       "      <td>23.685856</td>\n",
       "      <td>8.138688</td>\n",
       "      <td>7.981959</td>\n",
       "      <td>0.025578</td>\n",
       "      <td>7.524588</td>\n",
       "      <td>1.229900</td>\n",
       "      <td>4517.86560</td>\n",
       "      <td>...</td>\n",
       "      <td>9.256996</td>\n",
       "      <td>0.78764</td>\n",
       "      <td>0.670527</td>\n",
       "      <td>24.594488</td>\n",
       "      <td>72.611063</td>\n",
       "      <td>1965.343176</td>\n",
       "      <td>25.116750</td>\n",
       "      <td>37.155112</td>\n",
       "      <td>0.184622</td>\n",
       "      <td>737090.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>0.482849</td>\n",
       "      <td>2672.53426</td>\n",
       "      <td>546.663930</td>\n",
       "      <td>112.006102</td>\n",
       "      <td>8.138688</td>\n",
       "      <td>3.198099</td>\n",
       "      <td>0.116928</td>\n",
       "      <td>3.396778</td>\n",
       "      <td>7.948668</td>\n",
       "      <td>2818.01707</td>\n",
       "      <td>...</td>\n",
       "      <td>0.173229</td>\n",
       "      <td>1.14492</td>\n",
       "      <td>0.149006</td>\n",
       "      <td>13.673940</td>\n",
       "      <td>72.611063</td>\n",
       "      <td>6850.484442</td>\n",
       "      <td>45.745974</td>\n",
       "      <td>114.842372</td>\n",
       "      <td>21.978000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>617 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           AB          AF          AH          AM         AR        AX  \\\n",
       "0    0.209377  3109.03329   85.200147   22.394407   8.138688  0.699861   \n",
       "1    0.145282   978.76416   85.200147   36.968889   8.138688  3.632190   \n",
       "2    0.470030  2635.10654   85.200147   32.360553   8.138688  6.732840   \n",
       "3    0.252107  3819.65177  120.201618   77.112203   8.138688  3.685344   \n",
       "4    0.380297  3733.04844   85.200147   14.103738   8.138688  3.942255   \n",
       "..        ...         ...         ...         ...        ...       ...   \n",
       "612  0.149555  3130.05946  123.763599    9.513984  13.020852  3.499305   \n",
       "613  0.435846  5462.03438   85.200147   46.551007  15.973224  5.979825   \n",
       "614  0.427300  2459.10720  130.138587   55.355778  10.005552  8.070549   \n",
       "615  0.363205  1263.53524   85.200147   23.685856   8.138688  7.981959   \n",
       "616  0.482849  2672.53426  546.663930  112.006102   8.138688  3.198099   \n",
       "\n",
       "           AY         AZ          BC         BD   ...         FL        FR  \\\n",
       "0    0.025578   9.812214    5.555634  4126.58731  ...   7.298162   1.73855   \n",
       "1    0.025578  13.517790    1.229900  5496.92824  ...   0.173229   0.49706   \n",
       "2    0.025578  12.824570    1.229900  5135.78024  ...   7.709560   0.97556   \n",
       "3    0.025578  11.053708    1.229900  4169.67738  ...   6.122162   0.49706   \n",
       "4    0.054810   3.396778  102.151980  5728.73412  ...   8.153058  48.50134   \n",
       "..        ...        ...         ...         ...  ...        ...       ...   \n",
       "612  0.077343   8.545512    2.804172  4157.68439  ...   0.173229   1.26092   \n",
       "613  0.025882  12.622906    3.777550  5654.07556  ...  10.223150   1.24236   \n",
       "614  0.025578  15.408390    1.229900  5888.87769  ...   0.173229   0.49706   \n",
       "615  0.025578   7.524588    1.229900  4517.86560  ...   9.256996   0.78764   \n",
       "616  0.116928   3.396778    7.948668  2818.01707  ...   0.173229   1.14492   \n",
       "\n",
       "           FS         GB          GE            GF         GH          GI  \\\n",
       "0    0.094822  11.339138   72.611063   2003.810319  22.136229   69.834944   \n",
       "1    0.568932   9.292698   72.611063  27981.562750  29.135430   32.131996   \n",
       "2    1.198821  37.077772   88.609437  13676.957810  28.022851   35.192676   \n",
       "3    0.284466  18.529584   82.416803   2094.262452  39.948656   90.493248   \n",
       "4    0.121914  16.408728  146.109943   8524.370502  45.381316   36.262628   \n",
       "..        ...        ...         ...           ...        ...         ...   \n",
       "612  0.067730   8.967128  217.148554   8095.932828  24.640462   69.191944   \n",
       "613  0.426699  35.896418  496.994214   3085.308063  29.648928  124.808872   \n",
       "614  0.067730  19.962092  128.896894   6474.652866  26.166072  119.559420   \n",
       "615  0.670527  24.594488   72.611063   1965.343176  25.116750   37.155112   \n",
       "616  0.149006  13.673940   72.611063   6850.484442  45.745974  114.842372   \n",
       "\n",
       "            GL   Epsilon  \n",
       "0     0.120343  737137.0  \n",
       "1    21.978000       NaN  \n",
       "2     0.196941       NaN  \n",
       "3     0.155829       NaN  \n",
       "4     0.096614  737509.0  \n",
       "..         ...       ...  \n",
       "612  21.978000  737681.0  \n",
       "613   0.145340  737676.0  \n",
       "614  21.978000  737264.0  \n",
       "615   0.184622  737090.0  \n",
       "616  21.978000       NaN  \n",
       "\n",
       "[617 rows x 57 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_ = train.drop(['Class', 'Id'], axis=1)\n",
    "x_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_result = m.predict_proba(x_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.30352964e-05, 1.72162000e-05, 2.73801137e-05, 2.82384925e-05,\n",
       "       3.35695865e-05, 4.38997715e-05, 4.72764033e-05, 5.27616488e-05,\n",
       "       5.34000737e-05, 5.41088999e-05, 5.51586720e-05, 6.23063671e-05,\n",
       "       6.70547613e-05, 6.74401952e-05, 7.22836832e-05, 7.52162477e-05,\n",
       "       8.59316858e-05, 8.69686100e-05, 8.70547163e-05, 8.99489688e-05,\n",
       "       1.01002733e-04, 1.01307557e-04, 1.08810161e-04, 1.10770882e-04,\n",
       "       1.12007072e-04, 1.14112491e-04, 1.15067038e-04, 1.22590433e-04,\n",
       "       1.22830697e-04, 1.27246085e-04, 1.29644195e-04, 1.48863585e-04,\n",
       "       1.51135865e-04, 1.84804296e-04, 1.92266661e-04, 2.02236957e-04,\n",
       "       2.03461348e-04, 2.11336915e-04, 2.20248427e-04, 2.29990594e-04,\n",
       "       2.52079668e-04, 2.68318732e-04, 3.16008247e-04, 3.52871804e-04,\n",
       "       3.55292659e-04, 3.59230881e-04, 3.71835562e-04, 4.06282313e-04,\n",
       "       4.74438450e-04, 4.82345615e-04, 5.00442299e-04, 5.86447912e-04,\n",
       "       5.88989556e-04, 6.45866395e-04, 7.50806249e-04, 7.59038451e-04,\n",
       "       7.84978306e-04, 7.91496222e-04, 8.20618612e-04, 8.67197646e-04,\n",
       "       8.80743149e-04, 9.59263011e-04, 9.72787988e-04, 9.94009592e-04,\n",
       "       1.00482605e-03, 1.07660269e-03, 1.19458651e-03, 1.20006869e-03,\n",
       "       1.21942492e-03, 1.26710280e-03, 1.29525702e-03, 1.32750609e-03,\n",
       "       1.41651654e-03, 1.43712753e-03, 1.44187979e-03, 1.46733351e-03,\n",
       "       1.49605297e-03, 1.55052558e-03, 1.58309737e-03, 1.65208230e-03,\n",
       "       1.66395312e-03, 1.84834784e-03, 1.85969677e-03, 1.87387618e-03,\n",
       "       1.95982498e-03, 1.98963752e-03, 2.10233226e-03, 2.21374567e-03,\n",
       "       2.21712258e-03, 2.30196730e-03, 2.38590679e-03, 2.40126102e-03,\n",
       "       2.52555034e-03, 2.81402935e-03, 2.91346409e-03, 3.09943172e-03,\n",
       "       3.43760816e-03, 3.45341126e-03, 3.56159093e-03, 3.81130876e-03,\n",
       "       3.96683469e-03, 4.17108693e-03, 4.35001958e-03, 5.05148773e-03,\n",
       "       5.52043400e-03, 8.13965243e-03, 1.17051542e-02, 1.53266693e-02,\n",
       "       2.97853080e-02, 9.64796717e-02, 2.24300058e-01, 3.03150482e-01,\n",
       "       4.28114306e-01, 4.40540292e-01, 4.59382159e-01, 4.72921469e-01,\n",
       "       4.78962479e-01, 4.90541983e-01, 4.93817813e-01, 5.22089395e-01,\n",
       "       5.49192314e-01, 5.52285046e-01, 5.62281887e-01, 5.64657964e-01,\n",
       "       5.69461133e-01, 5.73639046e-01, 5.75179676e-01, 6.01273691e-01,\n",
       "       6.11378639e-01, 6.13109522e-01, 6.41333225e-01, 6.45186209e-01,\n",
       "       6.70930608e-01, 6.94863580e-01, 6.97906524e-01, 7.01567494e-01,\n",
       "       7.07696306e-01, 7.31585460e-01, 7.33602355e-01, 7.37877275e-01,\n",
       "       7.38161598e-01, 7.60616958e-01, 7.61764460e-01, 7.63607348e-01,\n",
       "       7.68456154e-01, 7.75990228e-01, 7.88517322e-01, 7.91990541e-01,\n",
       "       7.95413392e-01, 7.99665931e-01, 8.03191453e-01, 8.04134087e-01,\n",
       "       8.05219897e-01, 8.27591949e-01, 8.32018349e-01, 8.32997747e-01,\n",
       "       8.36536774e-01, 8.39000168e-01, 8.39022719e-01, 8.41368089e-01,\n",
       "       8.41519546e-01, 8.42522794e-01, 8.44529459e-01, 8.46292638e-01,\n",
       "       8.49779720e-01, 8.52258230e-01, 8.52620282e-01, 8.56304349e-01,\n",
       "       8.58902945e-01, 8.67320305e-01, 8.67722231e-01, 8.72206744e-01,\n",
       "       8.73998469e-01, 8.78725706e-01, 8.79403407e-01, 8.79576722e-01,\n",
       "       8.82490507e-01, 8.88149878e-01, 8.89201418e-01, 8.90469464e-01,\n",
       "       8.90472273e-01, 8.90556389e-01, 8.91681543e-01, 8.92201551e-01,\n",
       "       8.97006381e-01, 8.97034485e-01, 9.00218750e-01, 9.00620793e-01,\n",
       "       9.00689648e-01, 9.02694248e-01, 9.02729232e-01, 9.02847847e-01,\n",
       "       9.02980029e-01, 9.04148115e-01, 9.05141134e-01, 9.07210350e-01,\n",
       "       9.07279230e-01, 9.07531147e-01, 9.08876315e-01, 9.10349235e-01,\n",
       "       9.11353971e-01, 9.11874564e-01, 9.14677302e-01, 9.18112696e-01,\n",
       "       9.19528040e-01, 9.19819929e-01, 9.19831018e-01, 9.19967945e-01,\n",
       "       9.20012565e-01, 9.20804645e-01, 9.20813661e-01, 9.21532688e-01,\n",
       "       9.21580903e-01, 9.22331071e-01, 9.23185322e-01, 9.23759895e-01,\n",
       "       9.24442663e-01, 9.25395186e-01, 9.25949366e-01, 9.26894703e-01,\n",
       "       9.27006844e-01, 9.27752349e-01, 9.28210405e-01, 9.29109218e-01,\n",
       "       9.30842097e-01, 9.32223125e-01, 9.32519040e-01, 9.35140838e-01,\n",
       "       9.35711668e-01, 9.35912333e-01, 9.36372481e-01, 9.36437226e-01,\n",
       "       9.36828768e-01, 9.37384198e-01, 9.37403675e-01, 9.39157958e-01,\n",
       "       9.39588170e-01, 9.40163216e-01, 9.40493465e-01, 9.40711821e-01,\n",
       "       9.41045272e-01, 9.41180470e-01, 9.41372168e-01, 9.43320118e-01,\n",
       "       9.43338745e-01, 9.43517706e-01, 9.44150643e-01, 9.45121168e-01,\n",
       "       9.45749172e-01, 9.47061022e-01, 9.47915845e-01, 9.48172556e-01,\n",
       "       9.48594656e-01, 9.48669752e-01, 9.49032756e-01, 9.49349531e-01,\n",
       "       9.49952222e-01, 9.52340693e-01, 9.53423696e-01, 9.53443665e-01,\n",
       "       9.53722386e-01, 9.54007406e-01, 9.55238449e-01, 9.57811382e-01,\n",
       "       9.57863569e-01, 9.58188323e-01, 9.58244129e-01, 9.58374834e-01,\n",
       "       9.58524305e-01, 9.59577221e-01, 9.59728243e-01, 9.59853066e-01,\n",
       "       9.60334330e-01, 9.60343426e-01, 9.60442562e-01, 9.60485640e-01,\n",
       "       9.60599884e-01, 9.60808354e-01, 9.61428874e-01, 9.61491036e-01,\n",
       "       9.61567816e-01, 9.62143580e-01, 9.62394504e-01, 9.62431294e-01,\n",
       "       9.62946157e-01, 9.63085557e-01, 9.63125402e-01, 9.63429469e-01,\n",
       "       9.63431333e-01, 9.63629918e-01, 9.64026647e-01, 9.64383116e-01,\n",
       "       9.64447714e-01, 9.66019796e-01, 9.66323097e-01, 9.66332810e-01,\n",
       "       9.66363757e-01, 9.66702838e-01, 9.66720708e-01, 9.66789902e-01,\n",
       "       9.66977091e-01, 9.67001455e-01, 9.67227550e-01, 9.67811140e-01,\n",
       "       9.68096525e-01, 9.68106616e-01, 9.68312348e-01, 9.68783783e-01,\n",
       "       9.69267446e-01, 9.69787335e-01, 9.69852943e-01, 9.70186087e-01,\n",
       "       9.70315333e-01, 9.70376015e-01, 9.70575804e-01, 9.70782335e-01,\n",
       "       9.70930951e-01, 9.71569685e-01, 9.71815403e-01, 9.71855701e-01,\n",
       "       9.71985165e-01, 9.72537504e-01, 9.72924733e-01, 9.72926017e-01,\n",
       "       9.73329716e-01, 9.73462367e-01, 9.73542024e-01, 9.73839853e-01,\n",
       "       9.74059330e-01, 9.74085066e-01, 9.74203013e-01, 9.74780016e-01,\n",
       "       9.75164565e-01, 9.75370792e-01, 9.75376178e-01, 9.76211558e-01,\n",
       "       9.76789598e-01, 9.77068677e-01, 9.77292123e-01, 9.77498294e-01,\n",
       "       9.77533444e-01, 9.77559101e-01, 9.77583772e-01, 9.77711070e-01,\n",
       "       9.77727289e-01, 9.78713509e-01, 9.78769474e-01, 9.79236787e-01,\n",
       "       9.79267201e-01, 9.79379906e-01, 9.79455812e-01, 9.79952420e-01,\n",
       "       9.80103226e-01, 9.80626702e-01, 9.80639908e-01, 9.80644037e-01,\n",
       "       9.80748421e-01, 9.80790996e-01, 9.80854111e-01, 9.81000012e-01,\n",
       "       9.81304550e-01, 9.82284080e-01, 9.82328660e-01, 9.82403669e-01,\n",
       "       9.82424700e-01, 9.82588922e-01, 9.82941631e-01, 9.82942378e-01,\n",
       "       9.83194400e-01, 9.83251683e-01, 9.83298737e-01, 9.83492623e-01,\n",
       "       9.84228035e-01, 9.84526371e-01, 9.84573309e-01, 9.84702294e-01,\n",
       "       9.84755371e-01, 9.84832485e-01, 9.85091379e-01, 9.85163102e-01,\n",
       "       9.85315661e-01, 9.85348309e-01, 9.85423193e-01, 9.85457637e-01,\n",
       "       9.85538023e-01, 9.85587265e-01, 9.85620625e-01, 9.85627827e-01,\n",
       "       9.85917456e-01, 9.86087604e-01, 9.86149648e-01, 9.86347191e-01,\n",
       "       9.86624880e-01, 9.86768434e-01, 9.86794540e-01, 9.86955141e-01,\n",
       "       9.87004740e-01, 9.87093392e-01, 9.87171301e-01, 9.87258224e-01,\n",
       "       9.87383305e-01, 9.87487856e-01, 9.87506175e-01, 9.87762141e-01,\n",
       "       9.87972155e-01, 9.88101920e-01, 9.88493158e-01, 9.88699694e-01,\n",
       "       9.88728257e-01, 9.88775228e-01, 9.88784792e-01, 9.88819701e-01,\n",
       "       9.88959748e-01, 9.89126671e-01, 9.89209935e-01, 9.89277828e-01,\n",
       "       9.89299257e-01, 9.89536480e-01, 9.89609812e-01, 9.89753097e-01,\n",
       "       9.90195174e-01, 9.90332489e-01, 9.90358093e-01, 9.90446770e-01,\n",
       "       9.90458622e-01, 9.90459501e-01, 9.90492812e-01, 9.90517484e-01,\n",
       "       9.90565168e-01, 9.90604149e-01, 9.90709275e-01, 9.90722708e-01,\n",
       "       9.90734184e-01, 9.90921328e-01, 9.90948062e-01, 9.91048586e-01,\n",
       "       9.91100220e-01, 9.91356823e-01, 9.91384291e-01, 9.91449004e-01,\n",
       "       9.91505648e-01, 9.91506339e-01, 9.91517200e-01, 9.91573414e-01,\n",
       "       9.91574102e-01, 9.91613642e-01, 9.91686366e-01, 9.91717657e-01,\n",
       "       9.91760477e-01, 9.91825400e-01, 9.91953022e-01, 9.92045494e-01,\n",
       "       9.92123980e-01, 9.92158170e-01, 9.92159249e-01, 9.92162712e-01,\n",
       "       9.92213581e-01, 9.92221633e-01, 9.92265815e-01, 9.92319051e-01,\n",
       "       9.92449180e-01, 9.92518080e-01, 9.92640097e-01, 9.92815476e-01,\n",
       "       9.92846275e-01, 9.92919863e-01, 9.92944608e-01, 9.93044226e-01,\n",
       "       9.93131367e-01, 9.93201462e-01, 9.93207171e-01, 9.93304516e-01,\n",
       "       9.93315981e-01, 9.93317359e-01, 9.93410688e-01, 9.93584850e-01,\n",
       "       9.93600009e-01, 9.93798963e-01, 9.93967473e-01, 9.94063120e-01,\n",
       "       9.94070052e-01, 9.94086773e-01, 9.94118253e-01, 9.94207994e-01,\n",
       "       9.94261592e-01, 9.94376272e-01, 9.94780247e-01, 9.94841741e-01,\n",
       "       9.94849543e-01, 9.94850503e-01, 9.94985619e-01, 9.95219594e-01,\n",
       "       9.95236802e-01, 9.95237524e-01, 9.95248125e-01, 9.95364511e-01,\n",
       "       9.95571474e-01, 9.95759034e-01, 9.95768262e-01, 9.95771180e-01,\n",
       "       9.95775905e-01, 9.95817978e-01, 9.95868967e-01, 9.95930847e-01,\n",
       "       9.95966711e-01, 9.96099302e-01, 9.96186864e-01, 9.96190687e-01,\n",
       "       9.96223628e-01, 9.96389495e-01, 9.96420707e-01, 9.96745507e-01,\n",
       "       9.96799859e-01, 9.96836340e-01, 9.96852630e-01, 9.96922647e-01,\n",
       "       9.96938633e-01, 9.96946566e-01, 9.96969255e-01, 9.96976353e-01,\n",
       "       9.96999654e-01, 9.97018592e-01, 9.97031891e-01, 9.97041918e-01,\n",
       "       9.97049874e-01, 9.97053150e-01, 9.97158466e-01, 9.97174826e-01,\n",
       "       9.97177070e-01, 9.97180544e-01, 9.97215385e-01, 9.97283839e-01,\n",
       "       9.97385137e-01, 9.97386072e-01, 9.97523841e-01, 9.97545017e-01,\n",
       "       9.97558259e-01, 9.97560733e-01, 9.97573878e-01, 9.97594233e-01,\n",
       "       9.97599256e-01, 9.97614850e-01, 9.97619476e-01, 9.97627108e-01,\n",
       "       9.97636121e-01, 9.97704416e-01, 9.97710904e-01, 9.97733847e-01,\n",
       "       9.97770481e-01, 9.97842524e-01, 9.97847491e-01, 9.97853893e-01,\n",
       "       9.97858369e-01, 9.97864912e-01, 9.97889504e-01, 9.97907233e-01,\n",
       "       9.97973382e-01, 9.98014751e-01, 9.98096698e-01, 9.98215693e-01,\n",
       "       9.98227514e-01, 9.98237482e-01, 9.98267088e-01, 9.98273111e-01,\n",
       "       9.98288829e-01, 9.98295356e-01, 9.98319748e-01, 9.98345759e-01,\n",
       "       9.98422741e-01, 9.98464446e-01, 9.98503550e-01, 9.98507570e-01,\n",
       "       9.98549344e-01, 9.98613982e-01, 9.98631805e-01, 9.98645319e-01,\n",
       "       9.98674119e-01, 9.98690877e-01, 9.98720439e-01, 9.98757291e-01,\n",
       "       9.98806511e-01, 9.98814536e-01, 9.98816035e-01, 9.98887024e-01,\n",
       "       9.98958146e-01, 9.98993111e-01, 9.99035017e-01, 9.99056828e-01,\n",
       "       9.99077440e-01, 9.99090966e-01, 9.99099661e-01, 9.99154138e-01,\n",
       "       9.99156007e-01, 9.99170886e-01, 9.99203380e-01, 9.99241650e-01,\n",
       "       9.99247178e-01, 9.99254541e-01, 9.99311555e-01, 9.99318935e-01,\n",
       "       9.99344807e-01, 9.99392184e-01, 9.99398599e-01, 9.99418466e-01,\n",
       "       9.99429770e-01, 9.99429977e-01, 9.99454939e-01, 9.99531508e-01,\n",
       "       9.99551405e-01, 9.99582652e-01, 9.99587243e-01, 9.99614329e-01,\n",
       "       9.99621971e-01, 9.99622376e-01, 9.99648163e-01, 9.99723005e-01,\n",
       "       9.99799521e-01])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = predict_result[:,0]\n",
    "th = [0] + np.unique(p)\n",
    "th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_probabilites:  [[0.7963629  0.09938298 0.02887731 0.07537684]\n",
      " [0.7963629  0.09938298 0.02887731 0.07537684]\n",
      " [0.7963629  0.09938298 0.02887731 0.07537684]\n",
      " [0.7963629  0.09938298 0.02887731 0.07537684]\n",
      " [0.79636294 0.09938297 0.02887731 0.07537682]]\n",
      "avg_probabilites.shape[1]:  4\n",
      "class_0_est_instances:  3.9818144\n",
      "others_est_instances:  1.0181856155395508\n",
      "new_probabilites:  [[0.2        0.09760792 0.02836154 0.07403055]\n",
      " [0.2        0.09760792 0.02836154 0.07403055]\n",
      " [0.2        0.09760792 0.02836154 0.07403055]\n",
      " [0.2        0.09760792 0.02836154 0.07403055]\n",
      " [0.20000001 0.09760791 0.02836153 0.07403053]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = m.predict_proba(test)\n",
    "\n",
    "p0 = y_pred[:,0]\n",
    "\n",
    "p0[p0 > 0.62] = 1\n",
    "p0[p0 < 0.26] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(test_ID, columns=['Id'])\n",
    "\n",
    "submission['class_0'] = p0\n",
    "submission['class_1'] = 1 - p0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "_work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
